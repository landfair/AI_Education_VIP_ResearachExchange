<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="icon" type="image/png" href="https://i.imgur.com/lMAoVCW.png">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI in Education VIP Research Exchange</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Montserrat', sans-serif;
            background-color: #f8f9fa;
            color: #2d2d2d;
            line-height: 1.7;
        }

        .fixed-header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 70px;
            background-color: white;
            border-bottom: 3px solid #57068c;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
            padding: 0 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            z-index: 1000;
        }

        .logo img {
            height: 60px;
            width: auto;
        }

        .header-title {
            color: #57068c;
            font-weight: 600;
            font-size: 1.4rem;
            opacity: 0;
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            transition: opacity 0.3s ease;
            letter-spacing: 0.5px;
        }

        .header-title.visible {
            opacity: 1;
        }

        .header-right {
            display: flex;
            gap: 15px;
            align-items: center;
            margin-left: auto;
            position: relative;
            z-index: 9999;
        }

        .search-field {
            padding: 8px 12px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
            width: 200px;
        }

        .contribute-btn {
            background-color: white;
            border: 2px solid #57068c;
            border-radius: 4px;
            padding: 10px 24px;
            font-family: 'Montserrat', sans-serif;
            color: #57068c;
            cursor: pointer;
            transition: all 0.2s ease;
            font-size: 0.85rem;
            font-weight: 600;
            letter-spacing: 0.3px;
            text-transform: uppercase;
        }

        .contribute-btn:hover {
            background-color: #57068c;
            color: white;
        }

        .breadcrumb-subheader {
            position: fixed;
            top: 70px;
            left: 0;
            right: 0;
            height: 40px;
            background-color: #f0f0f5;
            border-bottom: 1px solid #ddd;
            padding: 0 20px;
            display: flex;
            align-items: center;
            z-index: 999;
            display: none;
        }

        .breadcrumbs {
            display: flex;
            align-items: center;
            font-size: 14px;
            color: #666;
        }

        .breadcrumbs a {
            color: #57068c;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumbs a:hover {
            color: #6600a8;
            text-decoration: underline;
        }

        .breadcrumbs .separator {
            margin: 0 8px;
            color: #999;
        }

        .breadcrumbs .current {
            font-weight: 600;
            color: #333;
        }

        body.show-breadcrumbs .breadcrumb-subheader {
            display: flex;
        }

        body.show-breadcrumbs main {
            margin-top: 110px;
        }

        main {
            margin-top: 70px;
            color: #333;
            transition: margin-top 0.3s;
        }

        h1, h2, h3 {
            font-family: 'Montserrat', sans-serif;
            color: #57068c;
        }

        a {
            color: #57068c;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .hero-banner {
            background: #57068c;
            color: white;
            padding: 60px 20px;
            text-align: center;
            position: relative;
            overflow: visible;
            z-index: 1;
        }

        .hero-banner::before {
            display: none;
        }

        .hero-content {
            position: relative;
            z-index: 2;
            max-width: 900px;
            margin: 0 auto;
        }

        .hero-banner h1 {
            color: white;
            font-size: 2.2rem;
            margin-bottom: 16px;
            font-weight: 600;
            letter-spacing: 0.5px;
        }

        .hero-banner p {
            font-size: 1rem;
            max-width: 700px;
            margin: 0 auto 25px;
            line-height: 1.7;
            color: rgba(255, 255, 255, 0.9);
            font-weight: 300;
        }

        .hero-search-container {
            position: relative;
            z-index: 9999;
            width: 100%;
            max-width: 500px;
            margin: 0 auto;
        }

        .hero-search-field {
            width: 100%;
            padding: 14px 20px;
            border-radius: 4px;
            border: none;
            font-size: 15px;
            font-family: 'Montserrat', sans-serif;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
        }

        .hero-search-container::after {
            content: "\f002";
            font-family: "Font Awesome 6 Free";
            font-weight: 900;
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            color: #57068c;
        }

        .content-section {
            padding: 40px 20px;
            max-width: 1200px;
            margin: 0 auto;
        }

        .section-title {
            text-align: center;
            margin-bottom: 30px;
            font-size: 1.75rem;
            color: #57068c;
            position: relative;
            padding-bottom: 15px;
            font-weight: 600;
            letter-spacing: 0.5px;
        }

        .section-title::after {
            content: "";
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 60px;
            height: 2px;
            background-color: #57068c;
        }

        .topic-categories {
                display: grid;
                grid-template-columns: repeat(2, 1fr);
                gap: 20px;
                margin-bottom: 20px;
                max-width: 800px;
                margin-left: auto;
                margin-right: auto;
            }

            .topic-categories.resources-grid {
                display: flex;
                justify-content: center;
                gap: 20px;
            }

            .topic-categories.resources-grid .topic-category {
                flex: 0 1 350px;
            }

            @media (max-width: 768px) {
                .topic-categories {
                    grid-template-columns: 1fr;
                    gap: 25px;
                }

                .topic-categories.resources-grid {
                    flex-direction: column;
                    align-items: center;
                }

                .topic-categories.resources-grid .topic-category {
                    width: 100%;
                    max-width: 350px;
                }
            }

            .topic-category h3 {
    font-size: 1.1rem;
    line-height: 1.3;
}

.subtopic-button {
    font-size: 16px;
    padding: 8px 12px;
    margin-bottom: 6px;
}

@media (max-width: 1200px) {
    .topic-category h3 {
        font-size: 1.2rem;
    }
    
    .subtopic-button {
        font-size: 18px;
        padding: 10px 15px;
        margin-bottom: 8px;
    }
}

        .topic-category {
            background-color: white;
            border-radius: 4px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.08);
            overflow: hidden;
            transition: all 0.2s ease;
            border: 1px solid #e5e5e5;
            position: relative;
        }

        .topic-category:hover {
            box-shadow: 0 4px 12px rgba(87, 6, 140, 0.12);
            border-color: #57068c;
            transform: translateY(-2px);
        }

        .category-header {
            background-color: transparent;
            padding: 24px 20px;
            position: relative;
        }

        .category-header h3 {
            color: #57068c;
            font-size: 1.1rem;
            margin: 0;
            padding-left: 36px;
            font-weight: 600;
            letter-spacing: 0.3px;
        }

        .category-icon {
            position: absolute;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 1.1rem;
            color: #57068c;
        }

        .subtopics-list {
            padding: 15px;
        }

        .subtopic-button {
            display: block;
            width: 100%;
            padding: 10px 15px;
            margin-bottom: 8px;
            border: none;
            background-color: transparent;
            cursor: pointer;
            font-family: 'Montserrat', sans-serif;
            font-size: 18px;
            text-align: left;
            border-radius: 4px;
            transition: all 0.2s ease;
            color: #333;
            position: relative;
            padding-left: 15px;
        }

        .subtopic-button:hover {
            background-color: transparent;
            color: #57068c;
            font-size: 18.1px;
        }

        .subtopic-button::before {
            display: none;
        }

        .landing-page {
            display: block;
        }

        .topic-pages {
            display: none;
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
        }

        body.show-topics .landing-page {
            display: none;
        }

        body.show-topics .topic-pages {
            display: block;
        }

        .topic-page-header {
            margin-bottom: 30px;
            text-align: center;
        }

        .topic-page-header h1 {
            font-size: 2.2rem;
            margin-bottom: 15px;
        }

        .topic-page-header p {
            font-size: 1.1rem;
            color: #555;
            max-width: 800px;
            margin: 0 auto;
        }

        .back-button {
            display: none;
        }

        .subtopic-cards {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 20px;
            margin-top: 30px;
            margin-bottom: 30px;
        }

        .subtopic-card {
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            overflow: hidden;
            transition: all 0.2s ease;
            border: 1px solid #eee;
            padding: 20px;
            cursor: pointer;
        }

        .subtopic-card:hover {
            box-shadow: 0 4px 12px rgba(137, 0, 225, 0.08);
            border-color: #e0d0eb;
        }

        .subtopic-card h3 {
            color: #57068c;
            font-size: 1.1rem;
            margin-bottom: 10px;
        }

        .subtopic-card p {
            color: #666;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .entry-pathways {
            padding: 60px 0;
            background-color: #f8f8fa;
        }
        
        .entry-pathways .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 0 20px;
            position: relative;
            overflow: visible;
        }
        
        .pathways-container {
            display: flex;
            overflow-x: auto;
            scroll-behavior: smooth;
            padding: 20px 0;
            -ms-overflow-style: none;
            scrollbar-width: none;
            gap: 20px;
            margin: 0 70px;
        }
        
        .pathways-container::-webkit-scrollbar {
            display: none;
        }
        
        .pathway-card {
            flex: 0 0 320px;
            background-color: white;
            border-radius: 8px;
            padding: 25px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
            border: 1px solid #eee;
            display: flex;
            flex-direction: column;
        }
        
        .pathway-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 15px rgba(137, 0, 225, 0.1);
            border-color: #e0d0eb;
        }
        
        .pathway-icon {
            width: 60px;
            height: 60px;
            background-color: #f0e6ff;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
        }
        
        .pathway-icon i {
            font-size: 24px;
            color: #57068c;
        }
        
        .pathway-title {
            font-size: 1.2rem;
            color: #57068c;
            margin-bottom: 10px;
            font-weight: 600;
        }
        
        .pathway-card p {
            color: #666;
            font-size: 0.9rem;
            line-height: 1.5;
            margin-bottom: 15px;
            flex-grow: 1;
        }
        
        .view-more {
            color: #57068c;
            text-decoration: none;
            font-weight: 500;
            font-size: 0.9rem;
            transition: all 0.2s;
            display: inline-block;
            align-self: flex-start;
        }
        
        .view-more:hover {
            color: #6600a8;
            text-decoration: underline;
        }
        
        .pathway-nav {
            position: absolute;
            top: 60%;
            transform: translateY(-50%);
            width: 50px;
            height: 50px;
            background-color: rgba(255, 255, 255, 0.9);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            box-shadow: 0 3px 8px rgba(0, 0, 0, 0.15);
            z-index: 10;
            transition: all 0.3s ease;
            border: 1px solid #f0f0f0;
        }
        
        .pathway-nav:hover {
            background-color: white;
            box-shadow: 0 5px 12px rgba(137, 0, 225, 0.2);
            transform: translateY(-50%) scale(1.05);
        }

        .pathway-nav.prev {
            left: 25px;
        }

        .pathway-nav.next {
            right: 25px;
        }

        .pathway-nav i {
            color: #57068c;
            font-size: 1.2rem;
        }

        .site-footer {
            background-color: #f2f2f2;
            padding: 60px 0 30px;
            border-top: 1px solid #dedede;
            margin-top: 60px;
        }
    
        .site-footer .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
    
        .footer-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 40px;
            margin-bottom: 40px;
        }
    
        .footer-column h3 {
            color: #57068c;
            font-size: 1.2rem;
            margin-bottom: 20px;
            font-weight: 600;
        }
    
        .footer-links {
            list-style: none;
        }
    
        .footer-links li {
            margin-bottom: 12px;
        }
    
        .footer-links a {
            color: #444;
            text-decoration: none;
            transition: color 0.2s;
            font-size: 0.95rem;
        }
    
        .footer-links a:hover {
            color: #57068c;
            text-decoration: underline;
        }
    
        .footer-bottom {
            text-align: center;
            padding-top: 30px;
            border-top: 1px solid #dedede;
            color: #666;
            font-size: 0.9rem;
        }

        .bibliography-container {
            margin-top: 30px;
            padding: 20px;
        }
    
        .bib-entry {
            margin-bottom: 30px;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
            border: 1px solid #eee;
        }
    
        .bib-citation {
            font-size: 16px;
            line-height: 1.6;
            position: relative;
            padding: 20px;
            padding-right: 50px;
            background-color: #f0e6ff;
            border-radius: 8px 8px 0 0;
            margin-bottom: 0;
        }

        .bib-citation:hover {
            background-color: #e9ddf5;
        }

        .collapse-indicator {
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
            width: 12px;
            height: 12px;
            border-left: 2px solid #57068c;
            border-bottom: 2px solid #57068c;
            transform: translateY(-60%) rotate(-45deg);
            transition: transform 0.3s ease;
            cursor: pointer;
            user-select: none;
        }

        .collapse-indicator.expanded {
            transform: translateY(-40%) rotate(135deg);
        }

        .citation-text {
            flex: 1 1 auto;
            padding-right: 10px;
            min-width: 0;
        }

        .bib-button {
            padding: 8px 16px;
            background-color: white;
            border: 1px solid #57068c;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 500;
            color: #57068c;
            cursor: pointer;
            transition: all 0.25s ease;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            white-space: nowrap;
            box-shadow: 0 1px 3px rgba(137, 0, 225, 0.1);
        }

        .bib-button:hover {
            background-color: #f0e6ff;
            border-color: #57068c;
            transform: translateY(-2px);
            box-shadow: 0 3px 5px rgba(137, 0, 225, 0.15);
        }
    
        .bib-button:active {
            transform: translateY(0);
            box-shadow: 0 1px 2px rgba(137, 0, 225, 0.1);
        }
    
        .annotation-actions .bib-button::before {
            content: "\f06e";
            font-family: "Font Awesome 6 Free";
            font-weight: 900;
            margin-right: 6px;
            font-size: 12px;
        }
    
        @media (max-width: 768px) {
            .bib-citation {
                padding-right: 50px;
            }

            .annotation-actions {
                flex-direction: column;
                gap: 10px;
            }

            .bib-button,
            .add-perspective-btn {
                width: 100%;
                text-align: center;
            }
        }
    
        .bib-annotation-container {
            padding: 20px;
            border-top: none;
            background-color: white;
            display: none;
        }
    
        .bib-annotation {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid #e6d0f0;
            font-size: 15px;
            line-height: 1.6;
            color: #444;
        }

        .bib-annotation:last-of-type {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px dashed #e6d0f0;
        }

        /* Nested annotations (replies/responses in a thread) */
        .bib-annotation .bib-annotation {
            margin-top: 15px;
            margin-left: 20px;
            padding-left: 15px;
            border-left: 3px solid #e6d0f0;
            background-color: #fafafa;
        }

        /* Sibling annotations (multiple perspectives on same source) */
        .bib-annotation-container > .bib-annotation + .bib-annotation {
            margin-top: 15px;
            padding-top: 15px;
            border-top: 2px solid #e6d0f0;
        }
    
        .annotation-author {
            font-style: italic;
            color: #666;
            display: inline-block;
            margin-top: 5px;
            font-size: 14px;
        }
    
        .annotation-text {
            font-size: 15px;
            line-height: 1.6;
            color: #444;
        }
    
        .annotation-actions {
            display: flex;
            gap: 15px;
            justify-content: center;
            align-items: center;
            margin-top: 20px;
            padding-top: 15px;
            border-top: 1px dashed #e6d0f0;
        }

        .add-perspective-btn {
            background-color: white;
            border: 2px solid #57068c;
            border-radius: 20px;
            padding: 8px 20px;
            font-family: 'Montserrat', sans-serif;
            color: #57068c;
            cursor: pointer;
            transition: all 0.2s ease;
            display: inline-block;
            width: fit-content;
            margin: 0;
        }

        .add-perspective-btn:hover {
            background-color: #f0e6ff;
        }
        
        .source-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.7);
            z-index: 2000;
            justify-content: center;
            align-items: center;
        }
        
        .source-modal-content {
            background-color: white;
            width: 80%;
            max-width: 900px;
            height: 80%;
            border-radius: 8px;
            overflow: hidden;
            position: relative;
        }
        
        .source-modal-header {
            padding: 15px 20px;
            background-color: #57068c;
            color: white;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .source-modal-title {
            font-size: 1.2rem;
            font-weight: 600;
        }
        
        .close-modal {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
        }
        
        .source-iframe-container {
            width: 100%;
            height: calc(100% - 60px);
        }
        
        .source-iframe {
            width: 100%;
            height: 100%;
            border: none;
        }
    
        .popup {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.4);
            z-index: 2000;
            justify-content: center;
            align-items: center;
        }
        
        .popup-content {
            background-color: white;
            width: 90%;
            max-width: 800px;
            height: 80%;
            border-radius: 8px;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }
        
        .close-btn {
            position: absolute;
            top: 10px;
            right: 15px;
            font-size: 24px;
            cursor: pointer;
            color: #57068c;
            z-index: 2001;
        }

        .search-results-container {
            position: absolute;
            top: 100%;
            left: 0;
            width: 100%;
            max-height: 300px;
            overflow-y: auto;
            background-color: white;
            border-radius: 0 0 8px 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            z-index: 9999;
            display: none;
        }
        
        .search-result-item {
            padding: 12px 15px;
            border-bottom: 1px solid #eee;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        
        .search-result-item:hover {
            background-color: #f0e6ff;
        }
        
        .search-result-item:last-child {
            border-bottom: none;
        }
        
        .result-title {
            font-weight: 600;
            color: #57068c;
            margin-bottom: 3px;
        }
        
        .result-context {
            font-size: 0.85rem;
            color: #666;
        }
        
        .search-container {
            position: relative;
            z-index: 9999;
        }
        
        .highlight {
            background-color: #ffffcc;
            transition: background-color 2s;
        }

        #hero-search-results {
            position: absolute;
            top: 100%;
            left: 0;
            width: 100%;
            max-height: 300px;
            overflow-y: auto;
            background-color: white;
            border-radius: 0 0 8px 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            z-index: 9999;
            text-align: left;
        }

        .search-result-item {
            padding: 12px 15px;
            border-bottom: 1px solid #eee;
            cursor: pointer;
            transition: background-color 0.2s;
            text-align: left;
        }

        input[type="search"]::-webkit-search-cancel-button {
            -webkit-appearance: none;
            appearance: none;
            display: none;
        }

        input[type="search"] {
            -webkit-appearance: none;
            appearance: none;
        }

        .header-search-wrapper {
            position: relative;
            width: 40px;
            transition: width 0.3s ease;
            overflow: visible;
            margin-right: 15px;
        }

        .header-search-wrapper:hover,
        .header-search-wrapper:focus-within {
            width: 250px;
        }

        .header-search-icon {
            position: absolute;
            left: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: #57068c;
            font-size: 16px;
            pointer-events: none;
            z-index: 1;
        }

        #header-search {
            width: 100%;
            padding: 8px 12px 8px 35px;
            border: 1px solid #ddd;
            border-radius: 20px;
            font-size: 14px;
            background-color: white;
        }

        .header-right {
            display: flex;
            gap: 15px;
            align-items: center;
            margin-left: auto;
            position: relative;
            z-index: 9999;
        }

        #header-search-results {
            right: 0;
            left: auto;
            width: 250px;
        }

        .entry-count {
            margin-top: 10px;
            font-size: 0.9rem;
            color: white;
            opacity: 0.9;
            text-align: center;
        }

        .empty-content-placeholder {
            padding: 60px 20px;
            text-align: center;
        }
            
        .placeholder-message {
            max-width: 600px;
            margin: 0 auto;
            padding: 40px;
            background-color: #f9f6fc;
            border-radius: 8px;
            border: 1px solid #e0d0eb;
        }
            
        .placeholder-message h3 {
            color: #57068c;
            margin-bottom: 15px;
        }
            
        .placeholder-message p {
            color: #555;
            line-height: 1.6;
            margin-bottom: 20px;
        }

        .report-bug-btn {
            background-color: white;
            border: 2px solid #57068c;
            border-radius: 20px;
            padding: 8px 16px;
            font-family: 'Montserrat', sans-serif;
            color: #57068c;
            cursor: pointer;
            transition: all 0.2s ease;
            font-size: 0.9rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .report-bug-btn:hover {
            background-color: #f0e6ff;
        }

        .report-bug-btn i {
            font-size: 0.8rem;
        }

        .header-right {
            gap: 12px;
        }
    </style>
</head>
<body>
    <header class="fixed-header">
        <div class="logo">
            <a href="https://engineering.nyu.edu/vip-team/ai-education-1" target="_blank">                
                <img src="https://i.imgur.com/iIODsNl.png" alt="NYU Logo" />        
            </a>
        </div>
        <div class="header-title"></div>
        <div class="header-right">
            <div class="search-container header-search-wrapper">
                <i class="fas fa-search header-search-icon"></i>
                <input type="search" placeholder="Search..." class="search-field" id="header-search">
                <div class="search-results-container" id="header-search-results"></div>
            </div>
            <button class="report-bug-btn" onclick="window.open('https://docs.google.com/forms/d/e/1FAIpQLSfjcCOxnbbpWjvfhBAvo_5EXCoa7DY5ePUzjYa1UgXcqjy9hQ/viewform?usp=sharing', '_blank')">
                <i class="fas fa-bug"></i> Report Bug
            </button>
            <button class="contribute-btn">Contribute</button>
        </div>
    </header>

    <div class="breadcrumb-subheader">
        <div class="breadcrumbs">
            <a href="#" onclick="showLandingPage()">Home</a>
            <span class="separator">›</span>
            <a href="#" onclick="showTopicPage('topic1')">Topic</a>
            <span class="separator">›</span>
            <span class="current">Subtopic</span>
        </div>
    </div>

    <main>
        <div class="landing-page">
            <section class="hero-banner">
                <div class="hero-content">
                    <h1>AI in Education VIP Research Exchange</h1>
                    <p>A collaborative knowledge base for NYU's AI in Education VIP team.</p>
                    <div class="hero-search-container search-container">
                        <input type="search" placeholder="Search for topics, tools, or research..." class="hero-search-field" id="hero-search">
                        <div class="search-results-container" id="hero-search-results"></div>
                    </div>
                    <div class="entry-count">Search <span id="entry-counter">0</span> research entries</div>
                </div>
            </section>

            

            <section class="content-section">
                <h2 class="section-title">VIP Subteams & Research Areas</h2>
                <p style="text-align: center; max-width: 700px; margin: -15px auto 30px; color: #555; font-size: 1rem;">Understanding, predicting, and guiding the impact of generative AI in education through four complementary research pathways:</p>
                <div class="topic-categories">
                    <!-- Evaluating Tools -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('evaluating-tools')" style="cursor: pointer;">
                            <i class="fas fa-tools category-icon"></i>
                            <h3>Evaluating Tools <span data-count-target="evaluating-tools" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>

                    <!-- Understanding Users -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('understanding-users')" style="cursor: pointer;">
                            <i class="fas fa-users category-icon"></i>
                            <h3>Understanding Users <span data-count-target="understanding-users" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>

                    <!-- Assessing Impacts -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('assessing-impacts')" style="cursor: pointer;">
                            <i class="fas fa-chart-line category-icon"></i>
                            <h3>Assessing Impacts <span data-count-target="assessing-impacts" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>

                    <!-- Innovating EdTech -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('innovating-edtech')" style="cursor: pointer;">
                            <i class="fas fa-lightbulb category-icon"></i>
                            <h3>Innovating EdTech <span data-count-target="innovating-edtech" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>
                </div>
            </section>

            <section class="content-section">
                <h2 class="section-title">Background Resources</h2>
                <div class="topic-categories resources-grid">
                    <!-- Learning Science -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('learning-science')" style="cursor: pointer;">
                            <i class="fas fa-brain category-icon"></i>
                            <h3>Learning Science <span data-count-target="learning-science" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>

                    <!-- Research Methods & Resources -->
                    <div class="topic-category">
                        <div class="category-header" onclick="showTopicPage('research-methods')" style="cursor: pointer;">
                            <i class="fas fa-book category-icon"></i>
                            <h3>Research Methods & Resources <span data-count-target="research-methods" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <div class="topic-pages">
            <!-- Understanding Users -->
            <div id="understanding-users" style="display: none;">
                <div class="topic-page-header">
                    <h1>Understanding Users Attitudes & Behaviors</h1>
                    <p>These resources help us to answer questions like: How, and how much, are students and teachers using AI tools? What values, principles, and assumptions shape their engagement with AI tools?</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('understanding-users', 'general')">
                            <h3>General <span data-count-target="general" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>General perspectives on how people perceive and interact with AI systems.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('understanding-users', 'administrators')">
                            <h3>Administrators <span data-count-target="administrators" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Administrative perspectives on AI policy, implementation, and institutional change.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('understanding-users', 'students')">
                            <h3>Students <span data-count-target="students" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Understanding how students perceive and use AI tools in their learning processes.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('understanding-users', 'faculty')">
                            <h3>Faculty <span data-count-target="faculty" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Faculty attitudes toward AI integration and their teaching practice adaptations.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- General subtopic -->
            <div id="general" style="display: none;">
                <div class="topic-page-header">
                    <h1>General Perspectives on AI</h1>
                    <p>General perspectives on how people perceive and interact with AI systems.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="general,psychology,human-AI-interaction">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1093/jcmc/zmz026"
                                data-source-title="Rise of Machine Agency: A Framework for Studying the Psychology of Human–AI Interaction (HAII)">
                                Sundar, S. S. "Rise of Machine Agency: A Framework for Studying the Psychology of Human–AI Interaction (HAII)." <em>J. Comput.-Mediat. Commun.</em> 2020, <em>25</em>, 74–88.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="sundar2020-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper is useful for framing the psychological impact of increasingly powerful AI agents. The paper proposes a framework that measures two dimensions of agency in human AI interaction: "cognizance", or the perceived sentience and consciousness of the AI agent, and "autonomy", or the extend to which the agent can carry out tasks without prompts from a human user.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Faculty subtopic -->
            <div id="faculty" style="display: none;">
                <div class="topic-page-header">
                    <h1>Faculty Perspectives on AI</h1>
                    <p>Faculty attitudes toward AI integration and their teaching practice adaptations.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="faculty,TPACK,teacher-knowledge">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.chb.2022.107468"
                                data-source-title="Towards Intelligent-TPACK: An empirical study on teachers' professional knowledge to ethically integrate artificial intelligence (AI)-based tools into education">
                                Celik, I. "Towards Intelligent-TPACK: An empirical study on teachers' professional knowledge to ethically integrate artificial intelligence (AI)-based tools into education." <em>Comput. Hum. Behav.</em> 2023, <em>138</em>, 107468.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="celik2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper applies the well-established TPACK framework to the problem of AI integration in education. TPACK is a framework to describe teachers' knowledge needs in terms of their content knowledge (CK), their pedagogical knowledge (PK) and their technological knowledge (TK). This paper proposes a new AI-TPACK framework, and surveys 327 teachers to establish baseline measurements.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="faculty,teaching-tools,AI-adoption">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.33394/jollt.v9i4.4205"
                                data-source-title="AI-Assisted Tools for Teaching and Learning">
                                Fitria, T. N. (2021). "Artificial intelligence (AI) in education: Using AI tools for teaching and learning process." <em>Prosiding Seminar Nasional Pendidikan</em>, 3, 67-76.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="fitria2021-faculty-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This text came right before / at the forefront of AI being widely adopted and in populous common use in educational settings. It begins by outlining several use cases and existing technologies that are seen as 'innovations' that help save time and are efficient. The argument and clarity gained surrounds the philosophy that human teacher skills - delivering new knowledge and creativity is what should be valued, protected and continuously harped on. While systematic procedures that have historically been manual and necessary to do, might be what is significantly automated.
                                        The research ultimately takes a deeper dive/ inspection into the various forms of currently emerging edutech, to create philosophical commentary on its advantages and disadvantages, especially in its form / medium. Fitria offers commentary especially under the lens of, again, helpfulness in systematic procedure, vs what might create a distance from interacting with lucrative human teacher value. It mentions several somewhat niche technologies too for educational settings like voice assistants, and language translation between teachers and students that are intriguing.
                                        Its method and materials are mostly concerned with library research. That's a limitation.
                                        <div class="annotation-author">Cate Hackett 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="faculty,prompt-engineering,AI-literacy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s10639-024-12842-8"
                                data-source-title="Prompt Engineering for Educators">
                                Park, Y., & Choo, S. (2025). "Prompt engineering strategies for educators: Optimizing AI-assisted teaching tools." <em>Education and Information Technologies</em>, 30(1), 145-168.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="park2025-faculty-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper explores different prompt engineering strategies designed to benefit educators and how they interact with Large Language Models (LLMs). It introduces a number of different frameworks designed for different steps of prompt engineering, with the most important being CLEAR, PARTS, and REFINE. Together, these provide a comprehensive approach for educators to engage with LLMs.
                                        The PARTS framework stands for Persona, Aim, Recipients, and Theme. These terms are what you should follow when creating context for the LLM. Persona refers to setting the context of your prompt. Aim is setting the goal of the prompt and what you want the outcome to be. Recipients are who you want the outcome to be for as the AI can tailor its response for that audience. It's important to note to be very specific with this as the more specific it is, the more tailored the response can be. The next is Theme, where you describe the style, tone and any restrictions. These could include which voice to use, how the tone of the response should sound, and a word count. Finally, there's structure. This represents the desired format for the output. This can include, but not limited to, bullet points, a table, code, and a graph.
                                        The next framework, CLEAR, stands for Concise, Logical, Explicit, Adaptive, and Reflective. This is how your prompts should be structured, as creating clear and concise prompts help the LLM follow precise instructions and allows it to follow a clear flow and order of ideas. While some of these overlap with PARTS, keeping prompts concise and explicit are definitely important to keep in mind.
                                        The next framework is REFINE. This stands for Rephrase key words, Experiment with context and examples, Feedback loop, Inquiry questions, Navigate by iterations, and Evaluate and verify outputs. This comes after the initial prompt and output from the LLM. This framework is used to develop a new prompt to modify the output.
                                        Together, these frameworks create IDEA, which stands for Include essential PARTS, Develop with CLEAR prompts, Evaluate outputs and REFINE prompts, and Apply with accountability. The last part refers to making sure you are aware of the potential limitations and to make sure to use LLMs with responsibility.
                                        This research ultimately brings together different prompt engineering ideas to create an ultimate framework which I think should be taught to educators. Teaching these principles of prompt engineering can enable them to become designers of AI-Assisted learning, rather than regular consumers. By being able to adopt these frameworks, educators can develop somewhat of an AI literacy, the ability to understand and shape how AI produces information.
                                        <div class="annotation-author">Rohan Kapur 10/23/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Students subtopic -->
            <div id="students" style="display: none;">
                <div class="topic-page-header">
                    <h1>Student Perspectives on AI</h1>
                    <p>Understanding how students perceive and use AI tools in their learning processes.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="students,K-12,engagement,UTAUT2">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s10639-024-12950-2"
                                data-source-title="An explanatory study of factors influencing engagement in AI education at the K-12 Level: from the perspective of students">
                                Li, M.; Hu, Y.; Hu, W.; et al. "An explanatory study of factors influencing engagement in AI education at the K-12 Level: from the perspective of students." <em>Educ. Inf. Technol.</em> 2024.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="li2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper aims to understand what external and internal factors might influence a K-12 student's engagement with AI. To do so, the researchers surveyed 1,022 K-12 students across more than 100 different Chinese schools using the UTAUT2 model, and complemented these surveys with interviews of 15 K-12 students. The paper identifies 8 factors that significantly affect K-12 students' willingness to engage with AI.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="students,engagement,AI-teaching-assistant,higher-education">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/abs/2408.08551"
                                data-source-title="Enhancing Student Engagement Through Artificial Intelligence: A Case Study in Higher Education">
                                Nguyen, S. "Enhancing Student Engagement Through Artificial Intelligence: A Case Study in Higher Education." <em>ArXiv</em> 2024, abs/2408.08551.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="nguyen2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper describes a case study of students using an AI Teaching Assistant (AITA) in the author's class on organizational behavior. The author notes that students found the AITA very helpful with some limitations. However, the paper does not control for the novelty effect, or provide much data on how or how much the students used the AITA.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="students,creativity,AI-perception,secondary-education">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.3390/jintelligence10030065"
                                data-source-title="Creativity and Artificial Intelligence—A Student Perspective">
                                Marrone, R., Taddeo, V., & Hill, G. (2022). "Creativity and Artificial Intelligence—A Student Perspective." <em>Journal of Intelligence</em>, <em>10</em>(3), 65.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="marrone2022-students-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article explores how AI is involved with education by looking at focus groups of secondary school children. Their findings are similar to our current class discussions about AI, but it is especially insightful because these focus on younger students. The results point to 4 buckets: technological, social, affective, and learning. Students believed that AI could harm social skills, making people less capable of real-world communication, while others saw potential for AI as connection if used collaboratively. Their affective responses varied, students who understood AI felt comfortable and trusting toward it, whereas those unfamiliar with it felt anxious or fearful. They often equated AI with robots and futuristic machines, showing a limited understanding of its everyday uses. Overall, they viewed AI as technically advanced but not truly creative, though it could inspire or "spark" human creativity. The researchers also proposed a 4AI model that mirrors the 4C models of learning.
                                        <div class="annotation-author">Sabria Islam 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Administrators subtopic -->
            <div id="administrators" style="display: none;">
                <div class="topic-page-header">
                    <h1>Administrator Perspectives on AI</h1>
                    <p>Administrative perspectives on AI policy, implementation, and institutional change.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="administrators,policy,ethics,AI-education">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s40593-020-00216-z"
                                data-source-title="Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies">
                                Schiff, D. (2025). "Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="schiff2025-admin-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper analyzes 24 national AI policy strategies to explore the role education plays in policymaking, stating that the strategies focus more on "education for AI" rather than "AI for education" (AIED). This means that the strategies mainly emphasize on preparing a workforce skilled in AI technologies through training AI experts, reskilling workers, and promoting public AI literacy, but lack discussions about the ethical and social implications of AI applied within educational settings. The author argues for bridging the current policy gap by encouraging policymakers to integrate ethical considerations explicitly into the design, deployment, and governance of AI in education. This article pushes for a dual approach of investing in human capital for AI and harnessing AI responsively to improve education itself.
                                        <div class="annotation-author">Nasrin Alanna Aidi 10/23/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                        <p style="text-align: center; padding: 40px; color: #666; font-style: italic;">
                            More resources on administrative perspectives coming soon!
                        </p>
                    </div>
                </div>
            </div>

            <!-- Student Attitudes subtopic -->
            <div id="student-attitudes" style="display: none;">
                <div class="topic-page-header">
                    <h1>Student Attitudes & Behaviors</h1>
                    <p>Understanding how students perceive and use AI tools in their learning processes.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="new-members,user-research">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.chb.2024.108123"
                                data-source-title="Student Perceptions of ChatGPT in Academic Settings">
                                Cotton, D. R., Cotton, P. A., & Shipway, J. R. (2024). "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT." <em>Innovations in Education and Teaching International</em>, 61(2), 228-241.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="cotton2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study surveyed 2,500+ students across multiple universities to understand their perceptions and usage patterns of ChatGPT. Key findings include widespread adoption for academic tasks, concerns about academic integrity, and varying levels of AI literacy. The research reveals generational differences in AI comfort levels and highlights the need for institutional guidance.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Evaluating Tools -->
            <div id="evaluating-tools" style="display: none;">
                <div class="topic-page-header">
                    <h1>Evaluating AI Tools</h1>
                    <p>These resources help us to answer questions about the capabilities of generative AI tools, which tools perform better on certain tasks, and how well AI-detection works.</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'coding')">
                            <h3>Coding <span data-count-target="coding" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Evaluating AI tools' capabilities in programming, code generation, and debugging tasks.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'creativity')">
                            <h3>Creativity <span data-count-target="creativity" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Assessing AI's ability to generate creative content and support creative thinking processes.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'detection-tools')">
                            <h3>Detection Tools <span data-count-target="detection-tools" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Evaluation of AI detection technologies and their effectiveness in educational contexts.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'ethics-safety')">
                            <h3>Ethics / Safety <span data-count-target="ethics-safety" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Examining ethical considerations and safety concerns in AI tool deployment.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'equity-social-justice')">
                            <h3>Equity / Social Justice <span data-count-target="equity-social-justice" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Analyzing how AI tools impact educational equity and social justice issues.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'error-hallucination')">
                            <h3>Error / Hallucination <span data-count-target="error-hallucination" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Understanding AI errors, hallucinations, and accuracy limitations.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'reasoning')">
                            <h3>Reasoning <span data-count-target="reasoning" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Testing AI's logical reasoning, problem-solving, and critical thinking capabilities.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'usability')">
                            <h3>Usability <span data-count-target="usability" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Assessing user experience, interface design, and ease of use in AI tools.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'translation')">
                            <h3>Translation <span data-count-target="translation" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Evaluating AI translation capabilities and multilingual support quality.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('evaluating-tools', 'tutoring-instruction')">
                            <h3>Tutoring / Instruction <span data-count-target="tutoring-instruction" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Evaluating AI tutoring systems, instructional capabilities, and educational feedback quality.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Detection Tools subtopic -->
            <div id="detection-tools" style="display: none;">
                <div class="topic-page-header">
                    <h1>Detection Tools</h1>
                    <p>Evaluation of AI detection technologies and their effectiveness in educational contexts.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="detection,false-positives,assessment,watermarking">
                            <div class="bib-citation"
                                data-source-url="https://onlinelibrary.wiley.com/doi/epdf/10.1002/tl.20624"
                                data-source-title="Generative AI detection in higher education assessments">
                                Ardito, C. G. (2025). Generative AI detection in higher education assessments. <em>New Directions for Teaching and Learning</em>, <em>2025</em>, 11–28.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="ardito2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper explores the pitfalls of AI Detection software and offers remedies to the problem. It explains that AI Detection is both fragile and misaligned with how education is today. It states that detection with these softwares is unreliable, as students are able to avoid it by paraphrasing AI generated work, while non-fluent English writers are being flagged as their writing uses common English sentences. These inconsistencies make it almost impossible to prove whether AI is used or not, and often lead to false positives, and leave students anxious about their writing and left to deal with proving themselves to their professors that AI was not used. The author also disproves watermarking, a technique experts have suggested to help prove AI was used in writing by having GenAI tools leave a hidden signature in their writing. An example of a signature could be by first dividing a dictionary of words into 2 sets, and then alternating between the two when generating text. AI detection tools would then search for this signature and give a score based on that. However, watermarking isn't immune to paraphrasing, and additionally, there are already models released without watermarking, and implementing it would just lead to a new market of non-watermarked models, essentially making it hard to regulate.
<br><br>
This paper recommends shifting school work to in-person centered assessments, presentations, and having on-going check-ins for writing. This could limit the use of AI and lead to students writing on their own. Another approach to this issue, the paper suggests having transparent disclosures on the proper uses of AI. Having these set rules will help properly integrate AI into learning. As the paper mentions, AI mirrors the invention of the calculator, as like AI, it was at first looked down upon and considered cheating and banned in schools. However, a gradual shift in perception occurred where calculators were later accepted in schools and they began regulating its use and now see it as a tool to make mathematics more efficient. I think once we are past this period of AI slander and begin to see its potentials, creating clear and transparent guidelines for its use will bring down the uses for cheating and bring down our reliance on unreliable AI Detection tools.
                                        <div class="annotation-author">Rohan Kapur 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,impostor-bias">
                            <div class="bib-citation"
                                data-source-url="https://scholar.google.com/"
                                data-source-title="GenAI Mirage: The Impostor Bias and the Deepfake Detection Challenge">
                                Casu, M.; Guarnera, L.; Caponnetto, P.; Battiato, S. "GenAI Mirage: The Impostor Bias and the Deepfake Detection Challenge in the Era of Artificial Illusions." <em>Forensic Sci. Int. Digit. Investig.</em> 2024, <em>50</em>, 301795.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="casu2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper considers the impacts of "imposter bias," an emerging cognitive bias arising from the rapid proliferation of AI-generated media. Imposter bias describes the tendency to misidentify human-generated media as AI-generated. Implicitly, the essay asks us to recognize distrust of factual evidence as a problem as serious as the unquestioned acceptance of false evidence. The problem isn't (only) that we may be fooled by doctored photos or texts, but that we'll increasingly mistrust the genuine.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,perplexity">
                            <div class="bib-citation"
                                data-source-url="https://medium.com/"
                                data-source-title="Two minutes NLP: Perplexity explained with simple probabilities">
                                Chiusano, F. "Two minutes NLP: Perplexity explained with simple probabilities." <em>Medium dot com</em>. 2022.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="chiusano2022-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        A popular blogger explains "perplexity," one of the core concepts underlying most AI-detection tools. In short, perplexity describes a system's ability to predict the next word in a string of words. Underlying most AI-detection tools is the assumption that human-generated writing is somewhat less predictable than AI-generated writing. It's important to note that the concept of perplexity arose as a way to measure the quality of large-language models (because humans write with low-perplexity). (In my opinion, this necessarily disqualifies perplexity as a useful measure for detecting AI-writing).
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                    <div class="bib-annotation">
                                        <div class="annotation-text">
                                            The way this is written may be slightly misleading. Perplexity measures the model's literal "top predicted words" and checks how likely the actual next word is to be generated by the model. Lower perplexity means the text has lower "generation entropy". That is, the model has a high probability of generating that sequence. Humans inject noise that models don't naturally predict well, so they get higher perplexity. Modern models may deliberately raise entropy via RLHF. The current implementations of perplexity are miscalibrated, since they likely rely on GPT-2 perplexity. A differential perplexity test, such as a pure comparison of a non-chatbot transformer's perplexity and a modern chatbot's perplexity, is probably one of the strongest detection models possible.
                                            <div class="annotation-author">Srinivas Harish 9/19/2025</div>
                                        </div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,bias,non-native-speakers,equity">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/abs/2304.02819"
                                data-source-title="GPT detectors are biased against non-native English writers">
                                Liang, W.; Yuksekgonul, M.; Mao, Y.; Wu, E.; Zou, J. "GPT detectors are biased against non-native English writers." <em>arXiv:2304.02819</em>. 2023.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="liang2023-detection-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study evaluates the fairness of seven widely used GPT detectors by testing their performance on writing samples from both native and non-native English writers. The researchers' core finding is that these detectors are significantly biased against non-native English speakers. While the detectors are nearly perfect at identifying essays written by native speakers, they consistently misclassify the writing of non-native speakers as AI-generated. For instance, over half of the TOEFL essays written by non-native speakers were incorrectly flagged as AI-generated. The study suggests this bias occurs because detectors often rely on a metric called "perplexity," which measures linguistic complexity. Non-native writers tend to use less varied vocabulary and sentence structures, resulting in lower perplexity text that the detectors mistake for AI-generated content. The authors caution against using these tools in educational settings, as they risk unfairly penalizing non-native English speakers for academic misconduct.
                                        <div class="annotation-author">Josephine Li 10/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,false-positives">
                            <div class="bib-citation"
                                data-source-url="https://www.sciencedirect.com/"
                                data-source-title="The false positives and false negatives of generative AI detection tools">
                                Dalalh, D. "The false positives and false negatives of generative AI detection tools in education and academic research: The case of ChatGPT." <em>The International Journal of Management Education</em>. 2023, Volume 21 Issue 2.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="dalalh2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The study investigates false positives (human-written text incorrectly flagged as AI-generated) and false negatives (AI-generated text missed by detectors) in AI Detection, with a particular focus on its impact on academic research and education, where integrity is crucial. Running tests on the abstract and literature parts of research papers before 2022 (before the release of ChatGPT), researchers found that the literature section of papers was more likely to be flagged as AI-generated compared to abstracts. This shows that the "formulaic" style of literature reviews resembles AI writing more closely. Beyond the results of the experiment, this paper argues that the current definitions of plagiarism and authorship are outdated in the AI era, calling for combining plagiarism detection with AI-detection tools.
                                        <div class="annotation-author">Nasrin Alanna Aidi 9/25/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,evaluation">
                            <div class="bib-citation"
                                data-source-url="https://link.springer.com/"
                                data-source-title="Evaluating the efficacy of AI content detection tools">
                                Elkhatat, A.M.; Elsaid, K.; Almeer, S. "Evaluating the efficacy of AI content detection tools in differentiating between human and AI‑generated text." <em>International Journal for Educational Integrity</em>. 2023, pp. 1-17.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="elkhatat2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study evaluates how the top 5 used AI content detection tools (OpenAI, Writer, Copyleaks, GPTZero, and CrossPlag) distinguish between human-authored and AI-generated contents. The tools were evaluated on both paragraphs produced by ChatGPT models 3.5 and 4, as well as on human-written controls. Results shows that all the detection tools were better at predicting GPT 3.5 than GPT 4.0 and with inconsistent performance on human-written samples, which includes false positives too. This concludes ongoing challenges in AI Detection reliability with the advancement of text generation technology. The authors recommend combining AI-detection tools with Manual Review to keep the Academic Integrity intact.
                                        <div class="annotation-author">Unmesh Achar 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This empirical study investigates how well several commercially available AI-authorship-detection tools (for text) perform at distinguishing human- vs AI-written content. Specifically: 15 paragraphs each from ChatGPT 3.5 and 4 on a technical topic plus five human-written control paragraphs; tools by e.g., OpenAI, Writer, Copyleaks, GPTZero, CrossPlag were used. Results: the detectors were more accurate for GPT-3.5 than GPT-4, but when applied to the human-written control responses they yielded inconsistent results, including false positives. They conclude that detection tools still have substantial limitations as AI-generated content becomes more sophisticated.
                                        <div class="annotation-author">Yanze Wu 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,ALBERT,transformer">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/"
                                data-source-title="ALBERT: A Lite BERT for Self-supervised Learning of Language Representations">
                                Lan Z. et al. "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations" <em>ArXiv</em>. 2019.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="lan2019-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Transformer models like BERT and RoBERTa, used for AI text detection, achieve SOTA results by stacking dozens of "attention" layers together. However, prior work (ALBERT) has shown significant redundancy across these layers. Many parameters do not contribute meaningfully to representation or expressivity of the model. Furthermore, information flows strictly forward with no mechanism for later layers to talk to earlier layers or revisit information from earlier representations. The team should aim to fix this "weakness" with an improved architecture.
                                        <div class="annotation-author">Srinivas Harish 9/19/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,bias,fairness">
                            <div class="bib-citation"
                                data-source-url="https://peerj.com/"
                                data-source-title="The accuracy-bias trade-offs in AI text detection tools">
                                Pratama, A. R. "The accuracy-bias trade-offs in AI text detection tools and their impact on fairness in scholarly publication." <em>PeerJ Comput. Sci.</em> 2025, e2953.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="pratama2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study evaluates three AI text detection tools (GPTZero, ZeroGPT, and DetectGPT) and finds a significant trade-off between accuracy and bias. The tools flag text from non-native English speakers and certain academic disciplines as AI-generated, raising concerns about fairness in scholarly publication. All tools struggled with AI-assisted text and showed systemic bias. Abstracts from social sciences and those written by non-native English speakers had a significantly higher false positive rate, meaning that they were more likely to be incorrectly identified as AI-generated.
                                        <div class="annotation-author">Josephine Li 10/09/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,evasion,SICO,prompt-engineering">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/html/2305.10847v5/#S4"
                                data-source-title="Large language models can be guided to evade AI-generated text detection">
                                Lu, N., Liu, S., He, R., Ong, Y.-S., Wang, Q., & Tang, K. (2023). Large language models can be guided to evade AI-generated text detection [Preprint]. <em>arXiv</em>. https://doi.org/10.48550/arXiv.2305.10847
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="lu2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper introduces a concept named SICO (Substitution-based In-Context example Optimization). It is a novel and cost-efficient method for constructing prompts that guide large language models (LLMs) to evade AI-generated text detectors. The method automatically optimizes a few human-written examples to be less "AI-like", which are then used as in-context demonstrations for the LLM.
<br><br>
The research's strength is in demonstrating a significant vulnerability in existing detection systems. The study shows that prompts generated by SICO enabled GPT-3.5 to successfully bypass six different detectors, significantly outperforming baseline paraphrasing methods. A comprehensive human evaluation further confirmed that the SICO-generated text maintained human-level readability and task completion rates.
<br><br>
This work is valuable because it highlights that evasion can be achieved through simple prompt-guiding rather than external tools, and it provides a new, effective benchmark (SICO) for evaluating the robustness of future detectors.
<br><br>
It also connects well with several past papers I've found that looks into prompt engineering and using that to bypass AI-detection tools (through targeting perplexity and burstiness).
                                        <div class="annotation-author">Josephine Li 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,DetectGPT">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/"
                                data-source-title="DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature">
                                Mitchell, E.; Lee, Y.; Khazatsky, A.; Manning, C. D.; Finn, C. (2023). "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="mitchell2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper proposes DetectGPT, a detector that flags AI-generated text by checking whether a passage sits in a negative curvature region of a language model's log-probability function. Unlike classifier-based detectors, DetectGPT needs no extra training data—it uses only the target model's log-probs plus small perturbations from a secondary model. In evaluations (e.g., fake-news detection with GPT-NeoX-20B), the method improves zero-shot AUROC over prior baselines and provides a model-agnostic way to test text authenticity.
                                        <div class="annotation-author">Yanze Wu 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,perplexity">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/"
                                data-source-title="AI or Human? Detecting Machine-Generated Text Through Perplexity">
                                Rylander, A. "AI or Human? Detecting Machine-Generated Text Through Perplexity."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="rylander2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper investigates the effectiveness of using perplexity (a metric for how predictable text is to an AI model) as a method for detecting whether a piece of writing was generated by AI or a human. The core idea is that AI-generated text should be highly predictable (low perplexity) to its own model, while human writing is more varied and less predictable (high perplexity). The findings show this evaluation method is only reliable in highly controlled scenarios. For example, when the same AI model is used to both generate and evaluate the text. The paper notes that the separation between AI and human writing "becomes less clear" as soon as more varied sources are introduced, revealing the method's limitations.
                                        <div class="annotation-author">Josephine Li 10/22/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="detection,prompt-engineering">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/"
                                data-source-title="Detection Undermining via Prompt Engineering for Deepfake Text">
                                Weichert, J.; Dimobi, C. "Detection Undermining via Prompt Engineering for Deepfake Text." <em>arXiv</em>. 2024.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="weichert2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article rigorously evaluates three AI text detectors (Watermarking, ZeroGPT, and GPTZero) on their ability to distinguish human-written from AI-generated essays. Results show that paraphrasing attacks, including prompts designed to mimic "college student" style or intentionally increase perplexity, can dramatically raise the false negative rates of all detectors, making AI-generated writing much more likely to evade detection. For instance, ZeroGPT's false negative rate rose to nearly 90% with targeted paraphrasing. The paper warns educators against relying solely on AI detectors for plagiarism judgments, highlighting the ease with which detection can be bypassed and the risk of harm from false accusations.
                                        <div class="annotation-author">Josephine Li 10/22/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Equity / Social Justice subtopic -->
            <div id="equity-social-justice" style="display: none;">
                <div class="topic-page-header">
                    <h1>Equity / Social Justice</h1>
                    <p>Analyzing how AI tools impact educational equity and social justice issues.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="equity,bias,non-native-speakers">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/abs/2304.02819"
                                data-source-title="GPT detectors are biased against non-native English writers">
                                Liang, W.; Yuksekgonul, M.; Mao, Y.; Wu, E.; Zou, J. "GPT detectors are biased against non-native English writers." <em>arXiv:2304.02819</em>. 2023.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="liang2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study evaluates the fairness of seven widely used GPT detectors by testing their performance on writing samples from both native and non-native English writers. The researchers' core finding is that these detectors are significantly biased against non-native English speakers. While the detectors are nearly perfect at identifying essays written by native speakers, they consistently misclassify the writing of non-native speakers as AI-generated. For instance, over half of the TOEFL essays written by non-native speakers were incorrectly flagged as AI-generated. The study suggests this bias occurs because detectors often rely on a metric called "perplexity," which measures linguistic complexity. Non-native writers tend to use less varied vocabulary and sentence structures, resulting in lower perplexity text that the detectors mistake for AI-generated content. The authors caution against using these tools in educational settings, as they risk unfairly penalizing non-native English speakers for academic misconduct.
                                        <div class="annotation-author">Josephine Li 10/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Reasoning subtopic -->
            <div id="reasoning" style="display: none;">
                <div class="topic-page-header">
                    <h1>Reasoning</h1>
                    <p>Testing AI's logical reasoning, problem-solving, and critical thinking capabilities.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="reasoning,comparative-analysis,finance">
                            <div class="bib-citation"
                                data-source-url="https://journals.sagepub.com/"
                                data-source-title="ChatGPT vs. Students: A Comparative Analysis of Performance in Corporate Finance Exams">
                                Hussain, S. M.; Malik, A.; Ahmad, N.; Ahmed, S. "ChatGPT vs. Students: A Comparative Analysis of Performance in Corporate Finance Exams." <em>Journal of Educational Technology Systems</em>. 2025.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="hussain2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article focuses on a direct performance comparison between ChatGPT-4 and university students on corporate finance exams. One of the most striking findings was the stark contrast in performance based on question type. ChatGPT significantly outperformed students in descriptive questions (87.1% vs. 74.6%), demonstrating a clear strength in processing and summarizing conceptual, text-based information. However, this advantage completely reversed in numerical questions, where students vastly outperformed ChatGPT (81.6% vs. 31.9%). The authors conclude that ChatGPT relies on predicting likely answers from language patterns rather than performing actual calculations, leading to a fundamental failure in quantitative reasoning.
                                        <div class="annotation-author">Meiling Zhang 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Ethics / Safety subtopic -->
            <div id="ethics-safety" style="display: none;">
                <div class="topic-page-header">
                    <h1>Ethics / Safety</h1>
                    <p>Examining ethical considerations and safety concerns in AI tool deployment.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="ethics,guardrails,learning-harm">
                            <div class="bib-citation"
                                data-source-url="https://ssrn.com/abstract=4895486"
                                data-source-title="Generative AI Can Harm Learning">
                                Bastani, H., Bastani, O., Sungu, A., Ge, H., Kabakcı, Ö., & Mariman, R. (2024). Generative AI Can Harm Learning. <em>The Wharton School Research Paper</em>. https://doi.org/10.2139/ssrn.4895486
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="guardrails2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        A large field experiment in U.S. high-school math classes deployed two GPT-4 tutors for ~1,000 students: a general "GPT Base" chat interface and a guardrailed "GPT Tutor" designed with prompts to encourage learning behaviors. Results show a tradeoff: unguided assistance can boost practice performance yet undermine actual learning/retention, while structured guardrails can mitigate harms and better support learning objectives—evidence that design choices (not just model quality) matter in education.
                                        <div class="annotation-author">Yanze Wu 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="ethics,Frankenstein,policy,pedagogy">
                            <div class="bib-citation"
                                data-source-url="https://www.tandfonline.com/doi/full/10.1080/02188791.2023.2300137#d1e500"
                                data-source-title="Taming Frankenstein's monster: Ethical considerations relating to generative artificial intelligence in education">
                                Yang, Z., Wu, J. G., & Xie, H. (2024). Taming Frankenstein's monster: Ethical considerations relating to generative artificial intelligence in education. <em>Asia Pacific Journal of Education</em>, <em>45</em>(4), 1330–1343.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="yang2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper provides an overview of the ethical concerns that arise with the increased use of Generative AI (GAI) in higher education, and outlines a specific set of guidelines for mitigating the unintended consequences of AI in learning environments. The introduction of the paper grounds the analysis in the history of Science Fiction, and utilizes Frankenstein's monster as an allegory for the consequences of unregulated innovation. Mary Shelly's monster is quoted: "Beware; for I am fearless, and therefore powerful" - as a means of further driving the notion that GAI is currently unbounded and unregulated. From this initial literary reference the paper goes on to first define consciousness and thought - and relate this back to our understandings of GAI. The paper notes that it is imperative to distinguish between human thought and GAI and that as tech continues to evolve the line can become increasingly blurred. Following this definition the varying ethical concerns that arise with GAI use, within and outside of educational environments, are discussed. The central concerns outlined relate to sourcing and informational bias that can arise with the use of GAI. The paper uses the example of corporations intentionally creating bias in AI to sway public opinion as a means of exploring possible malicious uses of GAI, while other primary concerns focus on the unintended consequences of GAI use. The paper then poses general questions about regulation in the face of ethical concerns - who's responsible for regulating AI? The paper responds to these questions by outlining a set of guidelines to be implemented by both students and educators as a means of combating the consequences of AI use:
<br><br>
<strong>Submodel for educators:</strong><br>
- Equity concerns<br>
- Digital literacy<br>
- Enhance vigilance of bias<br>
- Pedagogy and assessment concerns<br>
- Encourage higher-order thinking<br>
- Incentivize the learning process<br>
- Strike a balance<br>
- Optimizing potential of technology<br>
- Establish a general policy<br>
- Set specific boundaries<br>
- Update policy regularly
<br><br>
<strong>Submodel for students:</strong><br>
- Preparation for using GAI<br>
- Improve awareness of limitations<br>
- Carry-out critical evaluation<br>
- Applying GAI<br>
- Seek out additional resources<br>
- Incorporate creativity and originality<br>
- Disclosure<br>
- Acknowledge and site sources properly
<br><br>
I found that the specific breakdown of responsibility for both educators and students to be well organized and thought out - I felt that the formatting gave a clear understanding of intention and a real attempt to find solutions and answers to questions which remain fairly open ended. I don't know if the literary introduction is as indicative of what the paper really seeks to argue - however I appreciate the reference and the greater thought framework it represents.
                                        <div class="annotation-author">Elan Hebert 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Usability subtopic -->
            <div id="usability" style="display: none;">
                <div class="topic-page-header">
                    <h1>Usability</h1>
                    <p>Assessing user experience, interface design, and ease of use in AI tools.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="usability,HCI,human-AI-interaction,machine-agency">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1093/jcmc/zmz026"
                                data-source-title="Rise of Machine Agency: A Framework for Studying the Psychology of Human-AI Interaction (HAII)">
                                Sundar, S. S. (2020). Rise of Machine Agency: A Framework for Studying the Psychology of Human-AI Interaction (HAII). <em>Journal of Computer-Mediated Communication</em>, 25(1), 74-88. https://doi.org/10.1093/jcmc/zmz026
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="sundar2020-usability-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article focuses on the shift in communication scholarship from "communication via" technology to "communicating with" technology, marking the transition to Human-AI Interaction (HAII). Media technologies have evolved from passive channels to active, intelligent agents with autonomous decision-making capabilities. The paper examines the fundamental tension between machine agency (AI's ability to personalize, recommend, and curate content independently) and human agency (users' desire for control and meaningful participation). It proposes adapting the Theory of Interactive Media Effects (TIME) to study HAII through two mechanisms: the "cue route" (how users perceive AI as a symbol—machine heuristics, transparency, interface cues) and the "action route" (how users engage with AI through collaboration, customization, and control exchanges).
<br><br>
The article critiques how increasing machine agency threatens human autonomy through privacy erosion, algorithmic opacity, automation bias (overtrusting machines), and algorithm aversion (rejecting algorithms even when optimal). Users often feel helpless against incomprehensible algorithms, experiencing "algorithmic anxiety" (Airbnb hosts) or unawareness of curation (Facebook feeds). To address this, the author advocates for human-AI collaboration: seeking user assent before automated decisions, increasing algorithmic transparency, enabling users to train and direct algorithms ("ground-truthing"), and pursuing mutual augmentation where humans and AI extend each other's capabilities. Trust built through deeper engagement (action route) proves more robust than perception alone (cue route), ultimately calling for co-creation that respects human agency while leveraging machine capabilities.
                                        <div class="annotation-author">Joseph Jiminian 10/16/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="usability,evaluation,AI-assistants,data-science,automation">
                            <div class="bib-citation"
                                data-source-url="https://openreview.net/forum?id=MB0TCLfLn1"
                                data-source-title="Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents">
                                Testini, I., Pacchiardi, L., & Hernandez-Orallo, J. (2025). Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents. <em>Transactions on Machine Learning Research</em>. https://openreview.net/forum?id=MB0TCLfLn1
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="testini2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This survey paper examines the landscape of evaluation methods and tools for large-language-model-based assistants and agents (especially in data-science contexts). Rather than detecting generation per se, it focuses on how we evaluate, benchmark, and characterise AI assistant performance (e.g., suggestion of methods, code generation, interpretation), including human-AI collaboration, levels of autonomy, and the tasks involved. It finds (1) a heavy focus on a small subset of goal-oriented activities, (2) limited study of intermediate human-AI collaboration modes, and (3) limited attention on automation via task transformation rather than substitution.
                                        <div class="annotation-author">Yanze Wu 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="usability,HCI,human-centered-AI,design">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/abs/2105.05424v1"
                                data-source-title="From Human-Computer Interaction to Human-AI Interaction: New Challenges and Opportunities for Enabling Human-Centered AI">
                                Xu, W., Dainoff, M. J., Ge, L., & Gao, Z. (2021). From Human-Computer Interaction to Human-AI Interaction: New Challenges and Opportunities for Enabling Human-Centered AI. <em>ArXiv</em>. https://arxiv.org/abs/2105.05424v1
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="xu2021-usability-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper summarizes what HCI professionals can contribute to human-AI interaction (HAII) including research, design, practice and policy. The authors argue that HCI professionals should act as advocates for human-centered values in the development and deployment of AI, particularly concerning data privacy and algorithmic equity.
                                        <div class="annotation-author">Alexander Landfair 12/2/2024</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article focuses on the role Human-Computer Interaction (HCI) professionals must play in developing human centered AI systems. The paper examines major challenges that distinguish AI system development from traditional computing systems: managing unique machine behaviors in AI, transitioning from simple interaction to human-AI collaboration and teaming, bridging human intelligence augmentation with AI, developing human machine hybrid intelligence, moving from UI usability to AI explainability and interpretability, shifting from automation to human-controlled autonomy, integrating ethical design principles, and creating intelligent interaction paradigms. Throughout these topics, the authors argue that AI systems possess fundamentally different characteristics, such as non deterministic behavior, learning capabilities, and autonomous decision making that require new HCI approaches beyond traditional design thinking.
<br><br>
The article critiques the AI and computer science communities for developing systems in isolation without adequate input from HCI professionals and behavioral scientists. It criticizes how machine behavior is primarily studied by those without formal behavioral science training, how "explainable AI" is often built for AI professionals rather than end users, how ML engineers are positioned as the "human at the center" instead of actual users, and how ethical guidelines lack practical implementation methods. The authors advocate for a Human-Centered AI (HCAI) approach where humans remain the ultimate decision makers, calling for HCI professionals to: leverage interdisciplinary expertise to translate psychological theories into computational models, develop human-in-the-loop systems that combine human and machine strengths, create meaningful human control mechanisms for autonomous systems, ensure AI explainability leads to true user comprehension, and apply iterative design methods with end users throughout AI development rather than as an afterthought. The paper emphasizes that effective AI systems require deep collaboration between HCI and AI professionals from the earliest stages of development.
                                        <div class="annotation-author">Joseph Jiminian 10/16/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Coding subtopic (placeholder) -->
            <div id="coding" style="display: none;">
                <div class="topic-page-header">
                    <h1>Coding</h1>
                    <p>Evaluating AI tools' capabilities in programming, code generation, and debugging tasks.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-code" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Evaluating Tools subteam is currently curating resources on AI coding capabilities. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Creativity subtopic (placeholder) -->
            <div id="creativity" style="display: none;">
                <div class="topic-page-header">
                    <h1>Creativity</h1>
                    <p>Assessing AI's ability to generate creative content and support creative thinking processes.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-palette" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Evaluating Tools subteam is currently curating resources on AI creativity and creative content generation. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Error / Hallucination subtopic -->
            <div id="error-hallucination" style="display: none;">
                <div class="topic-page-header">
                    <h1>Error / Hallucination</h1>
                    <p>Understanding AI errors, hallucinations, and accuracy limitations.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="hallucination,error,confabulation">
                            <div class="bib-citation"
                                data-source-url="https://pmc.ncbi.nlm.nih.gov/articles/PMC11681264/"
                                data-source-title="Is Artificial Intelligence Hallucinating?">
                                Özer, M. (2024). Is Artificial Intelligence Hallucinating? <em>National Library of Medicine</em>. Retrieved September 11, 2025.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="ozer2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article explores the causes and types of hallucinations that AI experiences. The article can be described as a literature review, although not super in depth. But I still think reading it is still extremely helpful to anyone who wants to understand the basics of AI hallucinations. Hallucinations are classified into intrinsic and extrinsic. Özer writes, "intrinsic hallucinations result in outputs that contradict the source content and the conversation history, while extrinsic hallucinations correspond to outputs whose accuracy cannot be verified based on the source content or conversation history." According to the author, conflicting information within the training data that is used on the AI is what can cause hallucinations. I feel like this point is quite obvious, since AI can be simplified to a mapping of relative probabilities of words. The author also suggests using a word other than "hallucination" to describe this phenomenon. They suggest "confabulation," since AI models don't have consciousness. In the conclusion, the author states that hallucinations can have varying degrees of impact on the user, based on what the user is using the AI for. The author brought up the example of using AI in the healthcare sector, but I found that confusing because, to my knowledge, generative AI isn't currently being in the diagnosis or treatment process.
                                        <div class="annotation-author">Yufei Huang 11/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Translation subtopic (placeholder) -->
            <div id="translation" style="display: none;">
                <div class="topic-page-header">
                    <h1>Translation</h1>
                    <p>Evaluating AI translation capabilities and multilingual support quality.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-language" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Evaluating Tools subteam is currently curating resources on AI translation capabilities. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Tutoring / Instruction subtopic -->
            <div id="tutoring-instruction" style="display: none;">
                <div class="topic-page-header">
                    <h1>Tutoring / Instruction</h1>
                    <p>Evaluating AI tutoring systems, instructional capabilities, and educational feedback quality.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tutoring,assessment,measurement">
                            <div class="bib-citation"
                                data-source-url="https://www.ejmste.com/"
                                data-source-title="Exploring the Potential of Artificial Intelligence Tools in Educational Measurement and Assessment">
                                Owan, V. J., Abang, K. B., Idika, D. O., Etta, E. O., Bassey, B. A. "Exploring the Potential of Artificial Intelligence Tools in Educational Measurement and Assessment." <em>EURASIA Journal of Mathematics, Science and Technology Education</em>. 2023, em2307.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="owan2023-tutoring-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study evaluates how artificial intelligence tools are being integrated into educational measurement and assessment which revolutionizes the traditional practices. AI supports personalized learning, intelligent tutoring and automated grading which improves the speed and feedback quality. The authors noted down that the predictive analytics and natural language processing tools further gives individualized support and expand the assessment possibilities. Importantly, while AI streamlines many tasks, they emphasize the need for ethical safeguards, transparency and ongoing teacher involvement to counter the risks around privacy, fairness and overdependency on technology. The authors recommend Teacher training and a blend of human and AI analysis are recommended for best practices.
                                        <div class="annotation-author">Unmesh Achar 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="tutoring,feedback,writing">
                            <div class="bib-citation"
                                data-source-url="https://www.sciencedirect.com/"
                                data-source-title="Comparing the quality of human and ChatGPT feedback of students' writing">
                                Steiss, J.; Tate, T.; Graham, S.; Cruz, J.; Hebert, M.; Wang, J.; Moon Y.; Tseng, W.; Warschauer, M.; Olson, C. B. "Comparing the quality of human and ChatGPT feedback of students' writing." <em>Learning and Instruction</em>. 2024. 101894.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="steiss2024-tutoring-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study investigates the question of whether AI can serve as a viable tool for providing formative feedback on students' essays by comparing ChatGPT-3.5 feedback with teacher feedback. They evaluated the feedback based on five key criteria: being criteria-based, offering clear directions, accuracy, prioritization of essential features, and using a supportive tone. The key findings are that teacher feedback outperformed ChatGPT in four of the five categories. The only area where AI was stronger was "criteria-based," meaning that it was good at explicitly referencing writing rubrics and standards. Importantly, the study also found that the quality of ChatGPT's feedback varied depending on the quality of the essay; for example, ChatGPT struggled with accuracy on high-quality essays and a supportive tone on low-quality ones.
                                        <div class="annotation-author">Meiling Zhang 9/24/2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The study looked at how ChatGPT3.5's feedback on student essays compared to teacher feedback. They judged the feedback in five areas: whether it followed the criteria, gave clear directions, was accurate, prioritized what mattered most, and had a supportive tone. Teachers were stronger in almost every category, except for being "criteria-based," where ChatGPT did better because it directly tied back and connected to the feedback to rubrics and standards. The researchers also found that ChatGPT's performance depended on the quality of the essay because it sometimes gave less accurate feedback on strong essays and wasn't very supportive when commenting on weaker ones. In the reflection, Zhang mentions that AI is definitely useful and can save a lot of time, but it shouldn't replace the writing process we know (writing drafts, getting feedback, etc.). According to her, writing should be messy and all over the place, which is where its true beauty lies.
                                        <br><br>
                                        I think Zhang makes valid points about not relying on AI to completely change the way we write. The convenience is definitely tempting especially when you're stuck and don't know where to start. However, I think that true skill when it comes to writing comes from struggling to get something down, constant revisions, and hearing what other real humans have to say about it. I think this is where our creativity can really come out. I think that in the end, while ChatGPT and AI are useful tools that can definitely be integrated in some ways and forms, it is best for us humans to continue to learn how to develop our writing ourselves in the traditional way that we know of.
                                        <div class="annotation-author">Ethan Lu 10/01/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Assessing Impacts -->
            <div id="assessing-impacts" style="display: none;">
                <div class="topic-page-header">
                    <h1>Assessing Impacts</h1>
                    <p>These resources help us to answer questions like: What are the effects of AI tools on student learning outcomes? How do these tools impact academic integrity, assessment validity, and student wellbeing? What are the equity implications of AI adoption in education?</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('assessing-impacts', 'learning-outcomes')">
                            <h3>Learning Outcomes <span data-count-target="learning-outcomes" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Measuring how AI tools affect student learning, comprehension, and skill development.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('assessing-impacts', 'academic-integrity')">
                            <h3>Academic Integrity <span data-count-target="academic-integrity" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Assessment of AI's effect on academic honesty and institutional integrity measures.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('assessing-impacts', 'assessment-validity')">
                            <h3>Assessment Validity <span data-count-target="assessment-validity" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>How AI tools impact the reliability and validity of educational assessments and grading practices.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('assessing-impacts', 'student-wellbeing')">
                            <h3>Student Experience + Wellbeing <span data-count-target="student-wellbeing" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Impact of AI on student stress, motivation, confidence, and overall educational experience.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('assessing-impacts', 'equity-access')">
                            <h3>Equity + Access <span data-count-target="equity-access" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>How AI tools affect educational equity and access across different student populations.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Learning Outcomes subtopic -->
            <div id="learning-outcomes" style="display: none;">
                <div class="topic-page-header">
                    <h1>Learning Outcomes</h1>
                    <p>Measuring how AI tools affect student learning, comprehension, and skill development.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="learning-outcomes,learning-harm,guardrails,tutoring">
                            <div class="bib-citation"
                                data-source-url="https://ssrn.com/abstract=4895486"
                                data-source-title="Generative AI Can Harm Learning">
                                Bastani, H., Bastani, O., Sungu, A., Ge, H., Kabakcı, Ö., & Mariman, R. (2024). Generative AI Can Harm Learning. <em>The Wharton School Research Paper</em>. https://doi.org/10.2139/ssrn.4895486
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="bastani2024-outcomes-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        A large field experiment in U.S. high-school math classes deployed two GPT-4 tutors for ~1,000 students: a general "GPT Base" chat interface and a guardrailed "GPT Tutor" designed with prompts to encourage learning behaviors. Results show a tradeoff: unguided assistance can boost practice performance yet undermine actual learning/retention, while structured guardrails can mitigate harms and better support learning objectives—evidence that design choices (not just model quality) matter in education.
                                        <div class="annotation-author">Yanze Wu 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,mathematical-reasoning,LLM">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/abs/2402.00157"
                                data-source-title="Large Language Models for Mathematical Reasoning: Progresses and Challenges">
                                Ahn, J., Verma, R., Lou, R., Liu, D., Zhang, R., & Yin, W. (2024). Large Language Models for Mathematical Reasoning: Progresses and Challenges. In <em>Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop</em> (pp. 1-8). Association for Computational Linguistics.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="ahn2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article not only examines the progress of LLM's in mathematical reasoning but also its implications in regards to education. Specifically looking at Math Word Problems (MWP). These problems may include tables and/or geometric figures. The article examines how tokenization, pre-training, prompting techniques, interpolation and extrapolation, scaling laws, Chain of Thought (COT), and In-Context Learning (ICL) impact the reasoning of LLM's. These factors play a direct role in how well a model does with MWP's. The article then evaluates the advantages and disadvantages of LLM's in math education. One disadvantage is that LLM's may not suit a student's learning style, especially if they learn from hands-on activities or visual aids. Though, LLM's also introduce a 'conversational style' in problem-solving which is important in mathematics and can offer further insight into subjects like Calculus. This research is unique in its assessment of LLM's in math education while also offering insight into LLM performance with MWP's. Something I'm curious about after reading this article is how well various models perform on more theoretical math courses like Discrete Math or Analysis. The MWP's assessed have concrete solutions involving equations or numbers, but in more advanced math courses answers can just be words and symbols.
                                        <div class="annotation-author">Karen Maza Delgado 11/11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,ChatGPT,engagement,review">
                            <div class="bib-citation"
                                data-source-url="https://www.frontiersin.org/articles/10.3389/feduc.2024.1378230"
                                data-source-title="Exploring the impact of ChatGPT: conversational AI in education">
                                Bettayeb, A. "Exploring the impact of ChatGPT: conversational AI in education." <em>Frontiers in Education</em>. 2024.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="bettayeb2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This journal provides a literary review of a research study conducted between 2022-2023 on the specific impacts of ChatGPT on educational environments. The findings showed that the adaptable nature of ChatGPT had a positive impact on student learning, allowing for tailored learning experiences and increased accessibility for students due to the conversational mode of information retrieval. The study overall showed positive outcomes on student learning, while citing a number of persisting concerns largely in regards to the ethics of models like ChatGPT. The main ethical and practical concerns the study raises are those of bias and authorship and misinformation.
                                        <div class="annotation-author">Elan Hebert 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,PhD,achievement,higher-education">
                            <div class="bib-citation"
                                data-source-url="http://www.ijiet.org/vol14/IJIET-V14N3-2204.pdf"
                                data-source-title="Examining the Impact of OpenAI's ChatGPT on PhD Student Achievement">
                                Boubker, O.; Ben-Saghroune, H.; Bourassi, J.; Abdessadek, M.; Sabbahi, R.; Abdellah, M. "Examining the Impact of OpenAI's ChatGPT on PhD Student Achievement." <em>International Journal of Information and Education Technology</em>, 2024, <em>14</em>, 443–451.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="boubker2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article presents a study that explores the influence of ChatGPT on PhD students' performance and examines factors that motivate their usage as well as their level of satisfaction with the tool. They found that there was a direct positive effect of ChatGPT's perceived usefulness on ChatGPT use and PhD students' satisfaction. They found a significant positive relationship between students who use ChatGPT and satisfaction with the tool. Finally, they found that students who use ChatGPT and are satisfied with ChatGPT reported net benefits on their studies, like increasing productivity, enhancing performance, simplifying research tasks, and improving research quality.
                                        <div class="annotation-author">Jesse Noppe-Brandon 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,creativity,divergent-thinking">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.jcreat.2024.100089"
                                data-source-title="How does generative artificial intelligence impact student creativity?">
                                Habib, S.; Vogel, T.; Anli, X.; Thorne, E. "How does generative artificial intelligence impact student creativity?" <em>Journal of Creativity</em>, 2024.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="habib2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper presents a mixed-methods study that explores how ChatGPT-3 influences students' creative thinking abilities and confidence in a college-level creativity course. The authors found that using ChatGPT-3 significantly improved scores in all four creativity dimensions (fluency, flexibility, elaboration, originality). However, qualitative findings revealed that while AI boosted idea generation speed and provided inspiration, it sometimes weakened originality and creative confidence. The study concluded that AI can enhance divergent thinking but may also lead to overreliance and cognitive fixation, where students depend too much on AI-generated ideas.
                                        <div class="annotation-author">Dan Ahimbisibwe 10/16/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,ITS,tutoring,GPT-4,pedagogy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.3390/electronics13244876"
                                data-source-title="Advancing Generative Intelligent Tutoring Systems with GPT-4">
                                Liu, S., Guo, X., Hu, X., & Zhao, X. (2024). Advancing Generative Intelligent Tutoring Systems with GPT-4: Design, Evaluation, and a Modular Framework for Future Learning Platforms. <em>Electronics</em>, <em>13</em>(24), 4876.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="liu2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article presents a framework for designing an AI-assisted ITS using ChatGPT. It begins with a literature review of classical ITS, ChatGPT, and Intelligent ITS. It then breaks down the framework of how to design the system using ChatGPT. Four components are created: a content retriever which pulls information based on the topic the user is interested in; a data analyzer which monitors the user and generates a dynamic user profile; an instructional advisor, which adapts the difficulty and type of content based on the user's performance; a feedback assessor which generates reports based on the data analyzer and the instructional advisor. In order for the system to work, all data is generated as JSON files, where the prompts given to the models specify exactly what needs to be in the files, and they are iterated upon until they pass validation. This allows the different models to communicate with each other through lightweight JSON information.
<br><br>
The authors create an example ITS called the Socratic Playground for Learning (SPL), which implements this system. Through a user interface, students are able to interact with these models by defining, through a menu or a text box, what they are learning about or practicing. The student then engages in back-and-forth Socratic-style conversation. The questions presented to them dynamically scale in difficulty and complexity depending on their answers and responses.
<br><br>
To test this system, the authors involved 30 first-year students from the Faculty of Education at Central China Normal University, all majoring in Early Childhood Education. In order to measure the system's effectiveness quantitatively, all of these students were studying beginner English, and they were provided with a pre- and post-test before and after a week of using SPL for 30-40 minutes each day. The students were also provided with a survey asking questions grouped into effectiveness, engagement, adaptivity, satisfaction, and recommendation activity. By the end of the week, there was a significant improvement on the post-test. Effectiveness, engagement, and adaptivity were rated very high on the qualitative side, with recommendation accuracy just slightly below, and satisfaction received good but lower scores. The study showed the efficacy of the system, though there is no control group so it is hard to fully call it a causal relationship.
<br><br>
As the authors point out, it's interesting that the satisfaction scores were lower, and that highlights the importance of determining how to create systems that students actually want to use. It's unsurprising that they provided results, but figuring out how to design these systems in ways that can not just become tools for efficiency, but student-desired tools for better experiences in their education is paramount. My last review was about another ITS system that used text as an interface, and while one of the major issues of SPL is that the use of ChatGPT like this makes the system not applicable in lower resource environments, it's likely that a text-based system would score even lower on satisfaction. I will be interested in continuing to explore this idea of how to make these systems integrate into classrooms in ways that give students useful personalized attention, but don't detract from or change for the worse pedagogical practices that exist now.
                                        <div class="annotation-author">Jesse Noppe-Brandon 11/10/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,ai-tutoring,stem-education">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1145/3392063.3394400"
                                data-source-title="Using a Mixed-Reality AI System for STEM Education">
                                Yannier, N., Hudson, S. E., & Koedinger, K. R. (2020). "Active Learning is About More Than Hands-On: A Mixed-Reality AI System to Support STEM Education." <em>International Journal of Artificial Intelligence in Education</em>, 30(1), 74-96.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="yannier2020-outcomes-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The study's most effective approach, the Combined condition, interleaves hands-on construction with guided discovery to let students "learn the theory" and then "apply the theory". The AI acts as an intelligent tutor, orchestrating a structured predict-explain-observe-explain cycle to provide real-time, personalized feedback. This approach, enabled by AI, ensures that children don't just tinker; they actively engage with scientific principles. It led to a more than 10-fold improvement in tower-building skills compared to the minimally-guided hands-on condition alone, proving that adding interactive guidance to hands-on experiences makes them more effective for learning. Guidance for hands-on activities is often inconsistent in learning environments like museums or even in schools. Not all parents, museum staff, or teachers have the necessary scientific background to provide knowledgeable and consistent support to students. This variability in support creates an unequal learning experience for children.
                                        <div class="annotation-author">Muhammad Farhan 09/25/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,physics,problem-solving">
                            <div class="bib-citation"
                                data-source-url="https://www.compadre.org/per/items/detail.cfm?ID=16445"
                                data-source-title="Help or Hype? Students' Engagement and Perception of Using AI to Solve Physics Problems">
                                Qurat-ul-Ann Mirza, N. Sanjay Rebello. "Help or Hype? Students' Engagement and Perception of Using AI to Solve Physics Problems." <em>Physics Education Research Conference (PERC)</em>. 2025.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="mirza2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study explores how students use ChatGPT during a physics problem-solving task embedded in a formal assessment. The findings indicated that students who engaged with ChatGPT generally performed better than those who did not. In particular, students who provided more complete and contextual prompts experienced greater benefits. There was also the presence of incorrect AI-generated responses, which calls for evaluating AI output. These results suggest that while AI can be a valuable aid in problem solving, its effectiveness depends significantly on how students use it, reinforcing the need to incorporate structured AI literacy into STEM education.
                                        <div class="annotation-author">Dan Ahimbisibwe 10/08/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,AI-literacy,AI-education,curriculum,pedagogy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1002/aaai.70007"
                                data-source-title="AI Literacy as a Core Component of AI Education">
                                Tadimalla, S. Y., & Maher, M. L. (2025). AI Literacy as a Core Component of AI Education. <em>AI Magazine</em>, <em>46</em>(2). https://doi.org/10.1002/aaai.70007
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="tadimalla2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The authors of this research frame what it would look like to facilitate comprehensive teaching about AI, which I found to be a rare approach, but come to think of it extremely helpful. Why wouldn't we starting thinking about how we need to scaffold the education on these tools (and thus implementing)?! This framework would significantly educate the younger generations not only about all surrounding AI infrastructures, i.e. understanding their inner workings when it comes to computer science and machine learning, as well as "literacy" (literally how to effectively use it), ethics (think ownership and responsibility), cognitive learning and problem solving. What I found this research to be most helpful in was its defining and labeling of individuals' knowledge extent, and "well-roundedness", if you will. They strategically chart such labels for example "naive AI user", "AI ethicist", "AI engineer", "uninformed AI consumer" - just to name a few - based on the factors 1. Knowledge 2. Skills 3. Attitudes and 4. Social awareness ranging from technical to socio education. These definitions and frameworks get impressively granular and extensive in topics and detail, even proposing a 16 module lesson plan with at least 3 subtopics in each to cover.
<br><br>
I started liking the concept of the learning module (7) on prompt engineering - this is where I thought it would be leaning more toward what I was hoping for which is more about effectively using AI in learning and especially not just asking for a generation of body of work. This topic I felt this proposal failed at. Though, the rest of the modules, to me, felt to extensively and adequately cover policy, ethics, basic computer science, understanding models and engineering, and other more meta socio-perceptions and projections of AI.
<br><br>
CONCLUSION: Overall great opening to the conversation and foundation to being thinking of how to structure learning about AI - OPPORTUNITY to skew and expand upon it even more toward education and creating - - aka how can you teach about the learning and creating process with AI 😁?
                                        <div class="annotation-author">Cate Hackett 11/5/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="learning-outcomes,student-perceptions,higher-education">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.3390/educsci15030343"
                                data-source-title="The impact of artificial intelligence (AI) on students' academic development">
                                Vieriu, A. M., & Petrea, G. (2025). The impact of artificial intelligence (AI) on students' academic development. <em>Education Sciences</em>, <em>15</em>(3), 343.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="vieriu2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This study was conducted on 85 students at the National University of Science and Technology POLITEHNICA Bucharest, Romania, focusing on second-year Aerospace and Medical Engineering students with direct experience in AI-integrated learning environments. The study uses purposive sampling and a structured questionnaire with both closed and open-ended questions to evaluate AI usage, perceptions, and its impact on learning. Data was collected through a structured questionnaire comprising 11 items: seven closed-ended questions assessing perceptions, usage, and the effectiveness of AI tools; and four open-ended questions exploring experiences, expectations, and concerns.
<br><br>
It finds that 95.6% of students use AI in academic activities through virtual assistants (88.2%) and educational platforms (42.4%). Most of the participants use these tools weekly or daily, making AI an integral part of the educational process for tasks like homework, projects, and knowledge enhancement. While 80% of respondents agree that AI enhances their educational experience and 82.4% believe it improves academic performance, some express uncertainty or skepticism about its ultimate effects, including concerns about reducing critical thinking and accuracy issues. When asked for suggestions on improvement, most students suggest proper integration of AI in education, focusing on guided use that doesn't limit critical thinking. Overall, the majority of participants highlight both the positive influence on collaboration and learning efficiency, as well as challenges such as the need for reliable information and ethical use.
<br><br>
This paper gives valuable insight into the real-time experiences and perceptions of students who have direct exposure to AI-integrated learning environments, rather than relying solely on expert or educator perspectives. By using mixed-methods analysis across both closed and open-ended survey questions, it provides a nuanced account of how students engage with artificial intelligence for academic activities, covering not just usage statistics but also the emotional, ethical, and cognitive challenges and benefits they encounter. The study emphasizes student-driven recommendations for balanced and effective AI integration, including calls for enhanced training, reliability, and critical engagement. This makes it a key resource for educators and policymakers aiming to understand and responsibly advance AI adoption in education, learning from the people who would be most affected by these policies.
                                        <div class="annotation-author">Nasrin Alanna Aidi 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Innovating EdTech -->
            <div id="innovating-edtech" style="display: none;">
                <div class="topic-page-header">
                    <h1>Innovating EdTech</h1>
                    <p>This section catalogs existing AI-powered educational tools to help innovators understand the current landscape and identify market gaps. Unlike other sections focused on research evaluation, these pages describe tools and their capabilities to inform product development and innovation strategy.</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'ai-tutoring')">
                            <h3>AI Tutoring & Learning Support <span data-count-target="ai-tutoring" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Tools that act as instructors, mentors, or study aids including tutorbots, homework helpers, and adaptive learning systems.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'writing-content-generation')">
                            <h3>Writing & Content Generation Tools <span data-count-target="writing-content-generation" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Tools that help students create or refine text and media, including writing assistants and translation tools.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'detection-integrity')">
                            <h3>Detection Tools <span data-count-target="detection-integrity" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Tools that monitor or verify the authenticity of work, including AI-writing detectors and plagiarism checkers.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'organizational-productivity')">
                            <h3>Organizational & Productivity Tools <span data-count-target="organizational-productivity" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Tools that structure learning and manage large projects, such as note-taking and research assistants.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'feedback-assessment')">
                            <h3>Feedback & Assessment Tools <span data-count-target="feedback-assessment" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>AI that evaluates or comments on student work, including automated grading and feedback generators.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'accessibility-inclusion')">
                            <h3>Accessibility & Inclusion Tools <span data-count-target="accessibility-inclusion" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>AI that expands educational access through speech-to-text, captioning, and assistive technologies.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'learning-analytics')">
                            <h3>Classroom & Learning Analytics <span data-count-target="learning-analytics" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>AI systems that track and interpret educational activity, including analytics dashboards and early warning systems.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('innovating-edtech', 'scheduling')">
                            <h3>Scheduling <span data-count-target="scheduling" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Tools that facilitate appointment and meeting scheduling for educational contexts.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Prototype Development subtopic -->
            <div id="prototype-development" style="display: none;">
                <div class="topic-page-header">
                    <h1>Prototype Development</h1>
                    <p>Creating and iterating on educational technology prototypes that leverage AI.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="edtech-innovation,partnerships">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1145/3573051.3596191"
                                data-source-title="Design Principles for AI-Enhanced Educational Tools">
                                Kumar, S., Thompson, A., & Lee, J. (2024). "Human-centered design principles for AI-enhanced educational technologies." <em>Proceedings of the ACM Conference on Learning @ Scale</em>, 234-245.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="kumar2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper outlines key design principles for creating educational technologies that effectively integrate AI while maintaining pedagogical integrity. The authors emphasize transparency, user agency, and educational effectiveness over technological novelty. Essential reading for the Innovating EdTech subteam's prototype development work.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- AI Tutoring & Learning Support subtopic -->
            <div id="ai-tutoring" style="display: none;">
                <div class="topic-page-header">
                    <h1>AI Tutoring & Learning Support</h1>
                    <p>Tools that act as instructors, mentors, or study aids including tutorbots, homework helpers, and adaptive learning systems.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-description,learning-planner,higher-education,personalization">
                            <div class="bib-citation">
                                <strong>Context</strong> - Generative Learning Planner
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="context-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> A generative learning planner for higher education that creates AI-taught courses based on student preferences. Teachers upload material and teaching structure/vision to create learning plans; students receive personalized plans tailored to their needs.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers and students in higher education
                                        <br><br>
                                        <strong>Notes:</strong> Specifically designed for higher education. The cofounder is a post-graduate student from NYU's ITP program.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Feedback & Assessment Tools subtopic -->
            <div id="feedback-assessment" style="display: none;">
                <div class="topic-page-header">
                    <h1>Feedback & Assessment Tools</h1>
                    <p>AI that evaluates or comments on student work, including automated grading and feedback generators.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-description,browser-extension,grading,feedback,IEP">
                            <div class="bib-citation">
                                <strong>Brisk AI</strong> - Multi-Function Browser Extension
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="brisk-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> A web/browser extension with functions including writing inspection, feedback & grading, presentation making, IEP goal generator, and recommendation letter generator.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers and students
                                        <br><br>
                                        <strong>Notes:</strong> The homepage walks through all its functions extensively. It's helpful to see all the different types of specific actions the tool can do - this gives teachers ways of using AI that they don't have to think of themselves. A "quick option" effect that exhaustively presents AI possibilities.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Organizational & Productivity Tools subtopic -->
            <div id="organizational-productivity" style="display: none;">
                <div class="topic-page-header">
                    <h1>Organizational & Productivity Tools</h1>
                    <p>Tools that structure learning and manage large projects, such as note-taking and research assistants.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-description,course-assets,content-generation,teachers">
                            <div class="bib-citation">
                                <strong>Almanack</strong> - Course Asset Generator
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="almanack-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> Generates course assets including worksheets, activities, assessments, and slide-decks.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers
                                        <br><br>
                                        <strong>Notes:</strong> Higher education applicability unclear.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="tool-description,lesson-planning,IEP,assessment,teachers">
                            <div class="bib-citation">
                                <strong>Magic School AI</strong> - Lesson Planning & Assessment Suite
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="magicschool-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> Lesson planning, assessments, and IEP writing capabilities.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers
                                        <br><br>
                                        <strong>Notes:</strong> Really markets its "safeguards," evidence basis, and security with data. Higher education applicability unclear.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Writing & Content Generation Tools subtopic -->
            <div id="writing-content-generation" style="display: none;">
                <div class="topic-page-header">
                    <h1>Writing & Content Generation Tools</h1>
                    <p>Tools that help students create or refine text and media, including writing assistants and translation tools.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-description,writing-assistant,browser-extension,collaboration">
                            <div class="bib-citation">
                                <strong>QuillBot</strong> - AI Writing Assistant
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="quillbot-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> AI writing-specific tool that provides pop-up style recommendations as you write.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers, students, and general users - writing tool specifically, though perhaps not specifically tuned for formal academic settings.
                                        <br><br>
                                        <strong>Notes:</strong> Mainly operates as an extension with inline recommendations. Markets itself as a collaborator rather than "writing for you." Also marketed with strong intent on being responsible. Inclusive but not specifically for higher education.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Detection Tools subtopic -->
            <div id="detection-integrity" style="display: none;">
                <div class="topic-page-header">
                    <h1>Detection Tools</h1>
                    <p>Tools that monitor or verify the authenticity of work, including AI-writing detectors and plagiarism checkers.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-search" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Innovating EdTech subteam is currently curating resources on detection tools. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Accessibility & Inclusion Tools subtopic -->
            <div id="accessibility-inclusion" style="display: none;">
                <div class="topic-page-header">
                    <h1>Accessibility & Inclusion Tools</h1>
                    <p>AI that expands educational access through speech-to-text, captioning, and assistive technologies.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-universal-access" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Innovating EdTech subteam is currently curating resources on accessibility and inclusion tools. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Classroom & Learning Analytics subtopic -->
            <div id="learning-analytics" style="display: none;">
                <div class="topic-page-header">
                    <h1>Classroom & Learning Analytics</h1>
                    <p>AI systems that track and interpret educational activity, including analytics dashboards and early warning systems.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-description,school-platform,analytics,administration,surveillance">
                            <div class="bib-citation">
                                <strong>SchoolAI</strong> - Integrated School Platform
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="schoolai-tool-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        <strong>What it does:</strong> Comprehensive platform marketed to teachers, school leaders, and students with administrative oversight capabilities including rule setting and insight to student/teacher performance and status. Interface includes 'quick options' like rubric generator, multiple choice quiz builder, and text translator.
                                        <br><br>
                                        <strong>Target users:</strong> Teachers, school leaders, students, and administrators
                                        <br><br>
                                        <strong>Notes:</strong> Has a tab outlining use for higher education. The interface gives teachers ideas for AI possibilities through quick options. However, there are concerns about the rule setting, surveillance, and data collection on teachers/students from an administrative oversight standpoint when creating an infrastructure where students, teachers, and administrators are all on the platform.
                                        <div class="annotation-author">Cate Hackett 11/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Scheduling subtopic -->
            <div id="scheduling" style="display: none;">
                <div class="topic-page-header">
                    <h1>Scheduling</h1>
                    <p>Tools that facilitate appointment and meeting scheduling for educational contexts.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-calendar-alt" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Innovating EdTech subteam is currently curating resources on scheduling tools. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Placeholder for other subtopics -->
            <div id="faculty-perspectives" style="display: none;">
                <div class="topic-page-header">
                    <h1>Faculty Perspectives</h1>
                    <p>Faculty attitudes toward AI integration and their teaching practice adaptations.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-book-open" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Understanding Users subteam is currently curating resources for this research area. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Additional Understanding Users subtopics -->
            <div id="administrator-views" style="display: none;">
                <div class="topic-page-header">
                    <h1>Administrator Views</h1>
                    <p>Administrative perspectives on AI policy, implementation, and institutional change.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-book-open" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Understanding Users subteam is currently curating resources for this research area. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <div id="ai-competencies" style="display: none;">
                <div class="topic-page-header">
                    <h1>AI Competencies & Literacy</h1>
                    <p>Assessment of AI literacy levels and competency development across user groups.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="user-research,new-members">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.caeai.2023.100162"
                                data-source-title="AI Literacy Framework for Higher Education">
                                Long, D., & Magerko, B. (2020). "What is AI literacy? Competencies and design considerations." <em>Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</em>, 1-13.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="long2020-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This foundational paper defines AI literacy as a set of competencies enabling individuals to critically evaluate AI technologies, communicate effectively with AI, and use AI as a tool online, at home, and in the workplace. The framework includes understanding AI capabilities, limitations, and ethical implications.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Additional Evaluating Tools subtopics -->
            <div id="genai-capabilities" style="display: none;">
                <div class="topic-page-header">
                    <h1>GenAI Tool Capabilities</h1>
                    <p>Assessment of what current generative AI tools can and cannot do for education.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-evaluation,impact-assessment">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.chb.2024.108234"
                                data-source-title="Capabilities and Limitations of Large Language Models">
                                Bommasani, R., Hudson, D. A., Adeli, E., et al. (2021). "On the opportunities and risks of foundation models." <em>arXiv preprint</em> arXiv:2108.07258.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="bommasani2021-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This comprehensive analysis examines foundation models (like GPT) across multiple dimensions including capabilities, limitations, and societal impacts. Essential reading for understanding what these models can and cannot do in educational contexts, including issues of bias, reliability, and appropriate use cases.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="tool-limitations" style="display: none;">
                <div class="topic-page-header">
                    <h1>Tool Limitations & Biases</h1>
                    <p>Understanding the constraints, biases, and failure modes of AI educational tools.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="tool-evaluation,ethics-policy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1145/3442188.3445922"
                                data-source-title="Bias in AI Systems: A Survey">
                                Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). "A survey on bias and fairness in machine learning." <em>ACM Computing Surveys</em>, 54(6), 1-35.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="mehrabi2021-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This survey provides a comprehensive overview of different types of bias in machine learning systems, sources of bias, and mitigation strategies. Particularly relevant for educational AI tools where bias can significantly impact student outcomes and educational equity.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="comparative-analysis" style="display: none;">
                <div class="topic-page-header">
                    <h1>Comparative Tool Analysis</h1>
                    <p>Side-by-side comparisons of different AI tools for specific educational tasks.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-book-open" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Evaluating Tools subteam is currently curating comparative studies. We welcome your tool evaluation research and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Additional Assessing Impacts subtopics -->
            <div id="academic-integrity" style="display: none;">
                <div class="topic-page-header">
                    <h1>Academic Integrity</h1>
                    <p>Assessment of AI's effect on academic honesty and institutional integrity measures.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="impact-assessment,partnerships">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s40979-023-00146-z"
                                data-source-title="Academic Integrity in the Age of AI">
                                Eaton, S. E. (2023). "Postplagiarism: Transdisciplinary ethics and integrity in the age of artificial intelligence and neurotechnology." <em>International Journal for Educational Integrity</em>, 19(1), 1-10.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="eaton2023-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Eaton proposes a "postplagiarism" framework for academic integrity in the AI era, arguing that traditional notions of plagiarism are insufficient for addressing AI-assisted work. The paper calls for new ethical frameworks that focus on learning outcomes rather than detection of AI use.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="academic-integrity,higher-education,dishonesty,cognitive-effects">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.54663/2182-9306.v11.n1.2025.pp156-175"
                                data-source-title="Use of Generative Artificial Intelligence tools in higher education environments">
                                Seco, D.; Grösser, S.; Pedrosa, A.M. "Use of Generative Artificial Intelligence tools in higher education environments." <em>Multidisciplinary Journal for Education, Social and Technological Sciences</em>. 2025, pages 156-175.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="seco2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper examines the integration of Gen AI into a university setting by analyzing its current applications and collecting perspectives from stakeholders like students and professors. The study finds that while AI is becoming increasingly common, its use remains somewhat limited. Students view AI as "valuable resource for personalized learning", while educators are focused on adapting their teaching methods to maintain quality in this new technological landscape. The research mentions a central tension between the significant potential of AI and its balance against major ethical concerns and risks. Key challenges include a rise in academic dishonesty, as AI provides new ways to cheat and plagiarize, and the risk of over-reliance on these tools, which can lead to negative cognitive effects like procrastination, memory decline, and decreased academic performance. The authors conclude that for AI to be integrated successfully, educators must evolve their assessment strategies to address these challenges, ensuring a student-centered approach that balances the technology's benefits and risks.
                                        The concerns raised by Seco et al. parallel the arguments from the Veritasium video and the issues of bias detailed by Baker & Hawn (2022). While the former two focus on how AI threatens the process of learning by eliminating cognitive effort and undermining academic integrity, Baker & Hawn reveal how AI can corrupt the equity of learning outcomes. Together, they expose a potential double bind for students, especially those from marginalized groups. A student might use an AI tool that allows them to bypass the "desirable difficulties" essential for deep system 2 thinking, and lead to academic dishonesty. Then, the same AI system could evaluate their work through a biased lens, systematically disadvantaging them based on their race, gender, or socioeconomic background. This creates a scenario where AI not only fails to support genuine learning but also actively perpetuates systemic inequality. Thus, the solution should be two-pronged, where we need the pedagogical shifts that Seco et al. and the Veritasium video imply, such as redesigning assessments to focus on process, but we also desperately need the technical and policy-level interventions that Baker & Hawn advocate for to ensure the tools themselves are built on principles of fairness and equity.
                                        <div class="annotation-author">Josephine Li 10/01/2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper's insights align with urging institutions and professors to balance rapid adaptation of generative AI. Not only it offers personalized learning but also deep understanding of concepts that's crucial for employability. Seco et al also recommends student centered approaches for conducting assessments to foster deep reflective thinking. The authors emphasize a central tension: AI enhances flexibility and accessibility but also introduces serious concerns, including the risk of academic dishonesty, overreliance, and negative cognitive impacts. The paper concludes that universities must strategically balance innovation with integrity, guiding the sector toward inclusive, process-oriented, and human-centered education in the AI era.
                                        <div class="annotation-author">Debika Dharma Lingam 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="academic-integrity,detection,evasion,SICO">
                            <div class="bib-citation"
                                data-source-url="https://arxiv.org/html/2305.10847v5/#S4"
                                data-source-title="Large language models can be guided to evade AI-generated text detection">
                                Lu, N., Liu, S., He, R., Ong, Y.-S., Wang, Q., & Tang, K. (2023). Large language models can be guided to evade AI-generated text detection [Preprint]. <em>arXiv</em>. https://doi.org/10.48550/arXiv.2305.10847
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="lu2023-academic-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper introduces a concept named SICO (Substitution-based In-Context example Optimization). It is a novel and cost-efficient method for constructing prompts that guide large language models (LLMs) to evade AI-generated text detectors. The method automatically optimizes a few human-written examples to be less "AI-like", which are then used as in-context demonstrations for the LLM.
<br><br>
The research's strength is in demonstrating a significant vulnerability in existing detection systems. The study shows that prompts generated by SICO enabled GPT-3.5 to successfully bypass six different detectors, significantly outperforming baseline paraphrasing methods. A comprehensive human evaluation further confirmed that the SICO-generated text maintained human-level readability and task completion rates.
<br><br>
This work is valuable because it highlights that evasion can be achieved through simple prompt-guiding rather than external tools, and it provides a new, effective benchmark (SICO) for evaluating the robustness of future detectors.
<br><br>
It also connects well with several past papers I've found that looks into prompt engineering and using that to bypass AI-detection tools (through targeting perplexity and burstiness).
                                        <div class="annotation-author">Josephine Li 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="academic-integrity,detection,false-positives,assessment">
                            <div class="bib-citation"
                                data-source-url="https://onlinelibrary.wiley.com/doi/epdf/10.1002/tl.20624"
                                data-source-title="Generative AI detection in higher education assessments">
                                Ardito, C. G. (2025). Generative AI detection in higher education assessments. <em>New Directions for Teaching and Learning</em>, <em>2025</em>, 11–28.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="ardito2025-academic-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper explores the pitfalls of AI Detection software and offers remedies to the problem. It explains that AI Detection is both fragile and misaligned with how education is today. It states that detection with these softwares is unreliable, as students are able to avoid it by paraphrasing AI generated work, while non-fluent English writers are being flagged as their writing uses common English sentences. These inconsistencies make it almost impossible to prove whether AI is used or not, and often lead to false positives, and leave students anxious about their writing and left to deal with proving themselves to their professors that AI was not used. The author also disproves watermarking, a technique experts have suggested to help prove AI was used in writing by having GenAI tools leave a hidden signature in their writing. An example of a signature could be by first dividing a dictionary of words into 2 sets, and then alternating between the two when generating text. AI detection tools would then search for this signature and give a score based on that. However, watermarking isn't immune to paraphrasing, and additionally, there are already models released without watermarking, and implementing it would just lead to a new market of non-watermarked models, essentially making it hard to regulate.
<br><br>
This paper recommends shifting school work to in-person centered assessments, presentations, and having on-going check-ins for writing. This could limit the use of AI and lead to students writing on their own. Another approach to this issue, the paper suggests having transparent disclosures on the proper uses of AI. Having these set rules will help properly integrate AI into learning. As the paper mentions, AI mirrors the invention of the calculator, as like AI, it was at first looked down upon and considered cheating and banned in schools. However, a gradual shift in perception occurred where calculators were later accepted in schools and they began regulating its use and now see it as a tool to make mathematics more efficient. I think once we are past this period of AI slander and begin to see its potentials, creating clear and transparent guidelines for its use will bring down the uses for cheating and bring down our reliance on unreliable AI Detection tools.
                                        <div class="annotation-author">Rohan Kapur 11/13/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Assessment Validity subtopic -->
<div id="assessment-validity" style="display: none;">
    <div class="topic-page-header">
        <h1>Assessment Validity</h1>
        <p>How AI tools impact the reliability and validity of educational assessments and grading practices.</p>
    </div>
    <div class="topic-content">
        <div class="bibliography-container">
            <div class="bib-entry" data-tags="assessment-validity,measurement,educational-assessment">
                <div class="bib-citation"
                    data-source-url="https://doi.org/10.29333/ejmste/13428"
                    data-source-title="Exploring the Potential of Artificial Intelligence Tools in Educational Measurement and Assessment">
                    Owan, V. J., Abang, K. B., Idika, D. O., Etta, E. O., Bassey, B. A. "Exploring the Potential of Artificial Intelligence Tools in Educational Measurement and Assessment." <em>EURASIA Journal of Mathematics, Science and Technology Education</em>. 2023, em2307.
                    <span class="collapse-indicator"></span>
                </div>
                <div class="bib-annotation-container" id="owan2023-validity-annotation">
                    <div class="bib-annotation">
                        <div class="annotation-text">
                            This paper explores the potential of AI tools in educational measurement and assessment, examining how artificial intelligence can enhance the reliability, validity, and efficiency of assessment practices in educational settings.
                            <div class="annotation-author">VIP Assessing Impacts Team</div>
                        </div>
                    </div>
                    <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Student Experience + Wellbeing subtopic -->
<div id="student-wellbeing" style="display: none;">
    <div class="topic-page-header">
        <h1>Student Experience + Wellbeing</h1>
        <p>Impact of AI on student stress, motivation, confidence, and overall educational experience.</p>
    </div>
    <div class="topic-content">
        <div class="bibliography-container">
            <div class="bib-entry" data-tags="student-wellbeing,cognitive-offloading,critical-thinking">
                <div class="bib-citation"
                    data-source-url="https://doi.org/10.3390/soc15010006"
                    data-source-title="AI Tools in Society; Impacts on Cognitive Offloading and the Future of Critical Thinking">
                    Gerlich, M. "AI Tools in Society; Impacts on Cognitive Offloading and the Future of Critical Thinking." <em>Societies</em> 2025, <em>15</em>, 6.
                    <span class="collapse-indicator"></span>
                </div>
                <div class="bib-annotation-container" id="gerlich2025-annotation">
                    <div class="bib-annotation">
                        <div class="annotation-text">
                            This study looks at the implications of the overreliance on AI tools to users' critical thinking abilities. The study sought to explore two central claims: That high use of AI is correlated to decreased critical thinking abilities, and that cognitive offloading mediates the relationship between AI tool usage and critical thinking. The results of the study found that individuals who self-identified as having high reliance on AI tools consistently scored lower on the critical thinking tests than those who did not declare such a reliance. The study urged that as a result of the tested linkage between AI usage and decreased critical thinking, that precautionary protocols should be implemented to avoid overall degradation of individuals cognitive functions.
                            <div class="annotation-author">Elan Hebert 10/16/2025</div>
                        </div>
                    </div>
                    <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                </div>
            </div>
        </div>
    </div>
</div>

            <div id="equity-access" style="display: none;">
                <div class="topic-page-header">
                    <h1>Equity & Access Issues</h1>
                    <p>How AI tools affect educational equity and access across different student populations.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="impact-assessment,ethics-policy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.compedu.2024.105112"
                                data-source-title="Digital Divide in AI Education">
                                Rahimi, S., & Chen, L. (2024). "The AI divide: How socioeconomic factors influence access to and benefits from educational AI tools." <em>Computers & Education</em>, 205, 105112.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="rahimi2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This research examines how socioeconomic factors create disparities in AI tool access and effectiveness. The study finds that while AI tools promise to democratize education, they may actually exacerbate existing inequalities without intentional equity-focused implementation strategies.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="equity-access,algorithmic-bias,fairness">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s40593-021-00285-9"
                                data-source-title="Algorithmic Bias in Education">
                                Baker, R.S.; Hawn, A. "Algorithmic Bias in Education." <em>Int J Artif Intell Educ</em> 2022, <em>32</em>, 1052–1092.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="baker2022-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        It is clear that algorithmic bias can be harmful; from racial bias in sentencing decisions to gender bias in assigning credit limits. Bias can arise in the data collection, data preparation, model development, model evaluation, model post-processing, and model deployment stages. Having under-sampled groups in training data can result in representational bias. This follows in education, requiring modifying algorithms to be fair and reducing bias when predicting GPAs or dropout rates. Additionally, omitting data like socioeconomic background can result in fairer models. A current challenge in machine learning is determining how many members of an underrepresented group must be included in a combined model so that it is fair and reliable. Additionally, some underrepresented groups have yet to be studied, like children of immigrants or religious minorities. Ultimately, Groups of learners should not be oversimplified in educational datasets where feasible and can improve labeling. Although we cannot optimize for all definitions of fairness, there is still opportunity to improve significantly, as many algorithms do not even consider fairness. Unfortunately, there is "disincentive for the developers of learning systems to reveal the algorithmic biases in their systems" due to privacy and critique. Some solutions going forward are to include the use of reference data and avoiding bias in the labeling process by allowing the group being studied to conduct the data labeling.
                                        <div class="annotation-author">Karen Maza Delgado 9/24/2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article emphasizes higher education institutions' responsibilities in promoting ethical AI usage in classrooms. One key point the authors made was that penalizing students for using AI is less effective than raising awareness around the implications of overreliance on AI to prevent academic dishonesty from happening in the first place. On the flip side, previous research has shown that AI can assist educators as well, in tasks such as lesson planning and trend-mapping. The article suggests four main ways that AI can be used in the classroom as a tool, including creating role-play scenarios to prepare students for stressful workplace environments. Although this was not mentioned in the article, I would also argue that AI can be especially helpful in language learning classes, as it would reduce stress on the professor to simulate conversational exams, since an AI tool can be used to do so. A pattern I am seeing in both the real world and the article is that AI has the biggest comparative advantage when it comes to personalizing a student's learning plan. Whether it be conversations in a different language or degree mapping, AI is a powerful tool that is at every student's hands.
                                        <div class="annotation-author">Yufei Huang 10/03/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="equity-access,privatization,EdTech,critical-pedagogy">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.14324/LRE.18.2.04"
                                data-source-title="Artificial intelligence and the technological turn of public education privatization: In defence of democratic education">
                                Saltman, K.J. "Artificial intelligence and the technological turn of public education privatization: In defence of democratic education." <em>London Review of Education</em>, 2020, <em>18</em> (2): 196–208.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="saltman2020-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article highlights what the EdTech sphere does wrong. The author claims adaptive technology doesn't have as strong positive standardized tests results that we expect it to. He mentions that young students are not very interested in 2d digital learning, and also makes claims about how biometric pedagogies (using webcams to see if students are paying attention/responding well to lessons) are problematic. The root of what he is saying is that the increasing investment towards private EdTech is only to the detriment of true learning. His current qualms with the current integration of AI in Education sheds light on ways we can work around the detrimental, for-profit, neoliberal frameworks regarding tech in the education system.
                                        <div class="annotation-author">Sabria Islam 10/16/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Additional Innovating EdTech subtopics -->
            <div id="user-testing" style="display: none;">
                <div class="topic-page-header">
                    <h1>User Testing & Feedback</h1>
                    <p>Methods for testing educational prototypes with real users and gathering feedback.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="edtech-innovation,user-research">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1145/3573051.3596234"
                                data-source-title="User-Centered Design for Educational AI">
                                Nielsen, J., & Gilutz, S. (2024). "Usability testing methods for educational AI applications." <em>Proceedings of the CHI Conference on Human Factors in Computing Systems</em>, 456-467.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="nielsen2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This paper presents adapted usability testing methods specifically for educational AI applications. The authors emphasize the importance of testing with actual students and educators rather than general users, and provide frameworks for evaluating both usability and educational effectiveness.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="integration-strategies" style="display: none;">
                <div class="topic-page-header">
                    <h1>Integration Strategies</h1>
                    <p>Approaches for integrating new AI technologies into existing educational systems.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-book-open" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Innovating EdTech subteam is currently curating integration methodologies. We welcome your implementation research and case studies.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <div id="scalability-assessment" style="display: none;">
                <div class="topic-page-header">
                    <h1>Scalability Assessment</h1>
                    <p>Evaluating the potential for scaling educational technology innovations.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="edtech-innovation,impact-assessment">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1016/j.compedu.2024.105234"
                                data-source-title="Scaling Educational Innovations">
                                Clarke, J., & Dede, C. (2024). "Factors influencing the scalability of educational technology innovations." <em>Computers & Education</em>, 210, 105234.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="clarke2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This research identifies key factors that determine whether educational technology innovations can be successfully scaled. The authors present a framework for assessing technical, pedagogical, organizational, and financial scalability dimensions, with specific attention to AI-enhanced tools.
                                        <div class="annotation-author">Alexander Landfair, January 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Research Methods & Resources -->
            <div id="research-methods" style="display: none;">
                <div class="topic-page-header">
                    <h1>Research Methods & Resources</h1>
                    <p>These sources will help you identify a research gap, design appropriate research methodologies, interpret your findings, and find publication in a peer-reviewed journal.</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'literature-review')">
                            <h3>Literature Review Methods <span data-count-target="literature-review" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Systematic approaches to finding, evaluating, and synthesizing existing research in AI education.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'collaborative-research')">
                            <h3>Collaborative Research <span data-count-target="collaborative-research" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Best practices for team-based research, project management, and interdisciplinary collaboration.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'experimental-design')">
                            <h3>Experimental Design <span data-count-target="experimental-design" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Methods for designing controlled studies to test AI tool effectiveness and educational interventions.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'survey-design')">
                            <h3>Survey Design & Analysis <span data-count-target="survey-design" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Best practices for creating effective surveys and analyzing quantitative data in educational research.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'interview-focus-groups')">
                            <h3>Interview & Focus Group Methods <span data-count-target="interview-focus-groups" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Techniques for conducting qualitative interviews and focus groups with students, faculty, and administrators.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'data-analysis')">
                            <h3>Data Analysis Techniques <span data-count-target="data-analysis" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Statistical and qualitative analysis methods for educational research data and findings interpretation.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'research-ethics')">
                            <h3>Research Ethics & IRB <span data-count-target="research-ethics" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Ethical considerations and IRB approval processes for educational research involving human subjects.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('research-methods', 'academic-writing')">
                            <h3>Academic Writing & Publication <span data-count-target="academic-writing" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Guidelines for writing research papers, conference presentations, and academic publications.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Literature Review Methods subtopic -->
            <div id="literature-review" style="display: none;">
                <div class="topic-page-header">
                    <h1>Literature Review Methods</h1>
                    <p>Systematic approaches to finding, evaluating, and synthesizing existing research in AI education.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-book" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on literature review methodologies. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Collaborative Research subtopic -->
            <div id="collaborative-research" style="display: none;">
                <div class="topic-page-header">
                    <h1>Collaborative Research</h1>
                    <p>Best practices for team-based research, project management, and interdisciplinary collaboration.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-users" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on collaborative research practices. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Experimental Design subtopic -->
            <div id="experimental-design" style="display: none;">
                <div class="topic-page-header">
                    <h1>Experimental Design</h1>
                    <p>Methods for designing controlled studies to test AI tool effectiveness and educational interventions.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-flask" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on experimental design. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Survey Design & Analysis subtopic -->
            <div id="survey-design" style="display: none;">
                <div class="topic-page-header">
                    <h1>Survey Design & Analysis</h1>
                    <p>Best practices for creating effective surveys and analyzing quantitative data in educational research.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-chart-bar" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on survey design and analysis. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Interview & Focus Group Methods subtopic -->
            <div id="interview-focus-groups" style="display: none;">
                <div class="topic-page-header">
                    <h1>Interview & Focus Group Methods</h1>
                    <p>Techniques for conducting qualitative interviews and focus groups with students, faculty, and administrators.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-comments" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on interview and focus group methods. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Data Analysis Techniques subtopic -->
            <div id="data-analysis" style="display: none;">
                <div class="topic-page-header">
                    <h1>Data Analysis Techniques</h1>
                    <p>Statistical and qualitative analysis methods for educational research data and findings interpretation.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-chart-line" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on data analysis techniques. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Research Ethics & IRB subtopic -->
            <div id="research-ethics" style="display: none;">
                <div class="topic-page-header">
                    <h1>Research Ethics & IRB</h1>
                    <p>Ethical considerations and IRB approval processes for educational research involving human subjects.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-balance-scale" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on research ethics and IRB processes. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Academic Writing & Publication subtopic -->
            <div id="academic-writing" style="display: none;">
                <div class="topic-page-header">
                    <h1>Academic Writing & Publication</h1>
                    <p>Guidelines for writing research papers, conference presentations, and academic publications.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-pen-fancy" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Content in Development</h3>
                            <p>VIP Research Methods subteam is currently curating resources on academic writing and publication. We welcome your contributions and findings.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Share Your Research</button>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Learning Science -->
            <div id="learning-science" style="display: none;">
                <div class="topic-page-header">
                    <h1>Learning Science</h1>
                    <p>Background readings in the science of teaching and learning.</p>
                </div>
                <div class="topic-content">
                    <div class="subtopic-cards">
                        <div class="subtopic-card" onclick="showSubtopicPage('learning-science', 'writing-composition')">
                            <h3>Writing & Composition <span data-count-target="writing-composition" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Cognitive and developmental theories of writing processes and instruction.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('learning-science', 'cognitive-science')">
                            <h3>Cognitive Science <span data-count-target="cognitive-science" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Research on cognitive load, memory, creativity, and learning processes.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('learning-science', 'reading-literacy')">
                            <h3>Reading & Literacy <span data-count-target="reading-literacy" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Deep reading, textual interpretation, and the ethics of literary engagement.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('learning-science', 'educational-philosophy')">
                            <h3>Educational Philosophy <span data-count-target="educational-philosophy" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Philosophical foundations of education, purpose, measurement, and teacher agency.</p>
                        </div>
                        <div class="subtopic-card" onclick="showSubtopicPage('learning-science', 'ai-ml-foundations')">
                            <h3>AI/ML Foundations <span data-count-target="ai-ml-foundations" style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.7em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">0</span></h3>
                            <p>Technical foundations of AI and machine learning relevant to education.</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Writing & Composition subtopic -->
            <div id="writing-composition" style="display: none;">
                <div class="topic-page-header">
                    <h1>Writing & Composition</h1>
                    <p>Cognitive and developmental theories of writing processes and instruction.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="writing,cognitive-psychology,composition">
                            <div class="bib-citation"
                                data-source-url="https://www.jstor.org/stable/376357"
                                data-source-title="Writer-based prose: A cognitive basis for problems in writing">
                                Flower, L. (1979). "Writer-based prose: A cognitive basis for problems in writing." <em>College English</em>, <em>41</em>(1), 19-37.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="flower1979-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        In this seminal paper, Flower describes the core challenge of writing from a cognitive psychological perspective. In doing so, she challenges the dominant theories of writing development practiced by expressionists like Peter Elbow. It begins with a deceptively simple question, "If writing is simply the act of 'expressing what you think' or 'saying what you mean, why is writing often such a difficult thing to do?" Along with Janet Emig's work, Flower's early articles marked the beginning of composition's cognitive turn in the late 70s.
                                        <div class="annotation-author">Alexander Landfair July 27, 2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Flower explains that the difficulty in writing isn't a lack of ideas, but in "orchestrating" a cognitive transformation. Writing operates through networks, personal narratives, and words that are full of stories and meanings only we know. Many students, including myself, would input a raw, writer-based draft, and the AI can generate a more reader-oriented revision. However, this is the dangerous part. The real writing happens within the struggle of transforming internal monologue to words on paper.
                                        <div class="annotation-author">Meiling Zhang 9/24/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="writing,working-memory,automated-feedback">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.3758/BF03194058"
                                data-source-title="Improving the writing skills of college students">
                                Kellogg, R. T., & Raulerson III, B. A. (2007). "Improving the writing skills of college students." <em>Psychonomic Bulletin & Review</em>, <em>14</em>(2), 237-242.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="kellogg2007-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Advanced writing skills are an important aspect of academic performance as well as of subsequent work-related performance. In order to achieve higher levels of writing performance, the working memory demands of writing processes should be reduced so that executive attention is free to coordinate interactions among them. This can in theory be achieved through deliberate practice that trains writers to develop executive control through repeated opportunities to write and through timely and relevant feedback. Automated essay scoring software may offer a way to alleviate the intensive grading demands placed on instructors and, thereby, substantially increase the amount of writing practice that students receive.
                                        <div class="annotation-author">Author abstract</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="writing,metacognition,fluency,children">
                            <div class="bib-citation"
                                data-source-url="https://drive.google.com/file/d/example"
                                data-source-title="Functional Automaticity in Children's Writing: A Problem of Metacognitive Control">
                                McCutchen, D. (1988). "Functional Automaticity in Children's Writing: A Problem of Metacognitive Control." <em>Written Communication</em>. Vol. 5. No. 3. July 1988. P. 306-324.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="mccutchen1988-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        McCutchen argues that the challenges inherent to writing are importantly different from most other cognitive tasks. In most domains, mastery happens when subtasks become automated, able to be performed subconsciously. The key point here is that the subtasks of writing are not really eligible for automaticity, because writing subtasks are not routine or generalizable in the same ways. She proposes, therefore, that writing mastery stems from fluency rather than automaticity. The difference is that fluency involves maintaining metacognitive control.
                                        <div class="annotation-author">Alexander Landfair, August 5, 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="writing,working-memory,long-term-memory,expertise">
                            <div class="bib-citation"
                                data-source-url="https://doi-org.proxy.library.nyu.edu/10.1207/S15326985EP3501_3"
                                data-source-title="Knowledge, Processing, and Working Memory: Implications for a Theory of Writing">
                                McCutchen, D. (2000). "Knowledge, Processing, and Working Memory: Implications for a Theory of Writing." <em>Educational Psychologist</em>, <em>35</em>:1, 13-23.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="mccutchen2000-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article surveys writing research and attempts to sketch a principled account of how multiple sources of knowledge, stored in long-term memory, are coordinated during writing within the constraints of working memory. The concept of long-term working memory is applied to the development of writing expertise. Based on research reviewed, it is speculated that lack of fluent language generation processes constrains novice writers within short-term working memory capacity, whereas fluent encoding and extensive knowledge allow skilled writers to take advantage of long-term memory resources via long-term working memory.
                                        <div class="annotation-author">Author abstract</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="writing,college,novice-expert,longitudinal">
                            <div class="bib-citation"
                                data-source-url="http://links.jstor.org/sici?sici=0010-096X%28200409%2956%3A1%3C124%3ATNAEWT%3E2.0.CO%3B2-W"
                                data-source-title="The Novice as Expert: Writing the Freshman Year">
                                Sommers, N., & Saltz, L. (2004). "The Novice as Expert: Writing the Freshman Year." <em>College Composition and Communication</em>, <em>56</em>(1), 124-149.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="sommers2004-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        In this longitudinal study, Sommers and Saltz identify the key characteristics of the most successful college writing students. "We argue that students who make the greatest gains as writers throughout college (1) initially accept their status as novices and (2) see in writing a larger purpose than fulfilling an assignment." The paper explains how first-year writing classes foster these mindsets that promote the growth of writing skills.
                                        <div class="annotation-author">Alexander Landfair, Jul 27, 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Cognitive Science subtopic -->
            <div id="cognitive-science" style="display: none;">
                <div class="topic-page-header">
                    <h1>Cognitive Science</h1>
                    <p>Research on cognitive load, memory, creativity, and learning processes.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="cognitive-load,educational-technology,instructional-design">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s11423-019-09701-3"
                                data-source-title="Cognitive load theory and educational technology">
                                Sweller, J. (2020). "Cognitive load theory and educational technology." <em>Educational Technology Research and Development</em>, <em>68</em>(1), 1-16.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="sweller2020-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Here, Sweller argues for cognitive load theory (which describes the limitations of our working memory) as a central concern in classroom design. "Technology-based instruction used without reference to the instructional design principles that flow from human cognition," he says, "is likely to be random in its effectiveness." What a mic drop!
                                        <div class="annotation-author">Alexander Landfair, Jul 27, 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="creativity,AI,student-perspectives,secondary-education">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.3390/jintelligence10030065"
                                data-source-title="Creativity and Artificial Intelligence—A Student Perspective">
                                Marrone, R., Taddeo, V., & Hill, G. (2022). "Creativity and Artificial Intelligence—A Student Perspective." <em>Journal of Intelligence</em>, <em>10</em>(3), 65.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="marrone2022-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article explores how AI is involved with education by looking at focus groups of secondary school children. Their findings are similar to our current class discussions about AI, but it is especially insightful because these focus on younger students. The results point to 4 buckets: technological, social, affective, and learning. Students believed that AI could harm social skills, making people less capable of real-world communication, while others saw potential for AI as connection if used collaboratively. Their affective responses varied, students who understood AI felt comfortable and trusting toward it, whereas those unfamiliar with it felt anxious or fearful. They often equated AI with robots and futuristic machines, showing a limited understanding of its everyday uses. Overall, they viewed AI as technically advanced but not truly creative, though it could inspire or "spark" human creativity. The researchers also proposed a 4AI model that mirrors the 4C models of learning: Mini-AI (personal use), Little AI (creative collaboration with AI), Big-AI (Advanced AI in professional use), and Legendary-AI (transformative), which students often appreciated the applications of Big/Legendary (describing them as "futuristic robots"), but undervalued everyday AI. The researchers point to educators teaching with AI in mind.
                                        <div class="annotation-author">Sabria Islam 10/9/2025</div>
                                    </div>
                                </div>
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This qualitative grounded theory study explored secondary students' perceptions of artificial intelligence (AI) and creativity following an eight-week hands-on curriculum involving both domains. The analysis, based on 12 focus groups and 8 interviews, classified into four central dimensions of student thinking: social, affective, technological, and learning factors. Most students considered AI a useful augmentative tool, not a replacement for human creativity—yet their conception of AI was often limited to "robotic" or extraordinary systems, with little awareness of everyday AI.
                                        To frame the findings, the researchers mapped student conceptions of AI to a new "4AI Model," closely paralleling Kaufman and Beghetto's established 4C model of creativity (mini-c, little-c, Pro-c, Big-C). The 4C model describes creativity along a developmental spectrum, from personal insight (mini-c) to world-changing innovation (Big-C); similarly, the 4AI approach recognizes that students engage with AI at multiple levels, ranging from everyday feedback tools (Mini-AI) to legendary, society-transforming systems (Legendary-AI). Interpreting the results through this model shows that while students readily appreciate the marvels of advanced AI (e.g., AlphaGo or GPT), they undervalue—or simply overlook—the creative potential in routine, embedded AI applications that scaffold daily learning. Thus, the study provides empirical support for AI literacy curricula that not only demystify AI technology, but also teach students to recognize and leverage the full spectrum of AI–creativity interplay across classroom and professional contexts.
                                        <div class="annotation-author">Debika Dharma Lingam 10/15/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Reading & Literacy subtopic -->
            <div id="reading-literacy" style="display: none;">
                <div class="topic-page-header">
                    <h1>Reading & Literacy</h1>
                    <p>Deep reading, textual interpretation, and the ethics of literary engagement.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="reading,ethics,deep-reading,social-media">
                            <div class="bib-citation"
                                data-source-url="https://carlhendrick.substack.com/p/the-humility-of-the-page-the-lost?utm_source=share&utm_medium=android&r=1qe5uc&triedRedirect=true"
                                data-source-title="The Humility of the Page: The Lost Ethics of Deep Reading">
                                Hendrick, C. (2025). "The Humility of the Page: The Lost Ethics of Deep Reading." <em>The Learning Dispatch</em>.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="hendrick2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        In this anecdotal article learning scientist Carl Hendrick laments the lost art of deep reading. He argues that reading is a moral and ethical duty in that it is the practice of paying attention to the general other while it also transforms the participator into a more conscientious citizen. He argues that the nature of 'soulless' social media algorithms are at least one huge contributor to the problem of making us more like machines - shallower, and less compassionate - and therefore less human. The article connects to Mikhail Bakhtin's theories of Dialogism, Heteroglossia, and Polyphony, and to Pierre Hadot's philosophy: 'Only he who is capable of a genuine encounter with the other is capable of an authentic encounter with himself.'
                                        <div class="annotation-author">Paul Marinos, Sep 26, 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="Russian-literature,epistemology,communication,Dostoevsky">
                            <div class="bib-citation"
                                data-source-url="https://muse.jhu.edu/pub/427/article/816082/summary"
                                data-source-title="Dostoevskii, the Feuilleton and the Confession">
                                Zhernokleyev, D. (2021). "Dostoevskii, the Feuilleton and the Confession." <em>Slavonic and East European Review</em>, pp 71-97.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="zhernokleyev2021-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        Zhernokleyev analyzes communication, formalism, and epistemology in the work of Fyodor Dostoevsky. He argues that, from an epistemological level, communication itself is inherently violent, and that 'reality strives towards fragmentation'. He argues that there is an 'epistemic fallenness' inherent in our language and imagination, and he cites our givenness to fascination - deliberately taken advantage of with the genre of the Feuilleton - as being the primary reason for distraction, miscommunication, and fragmentation. This paper, like Dostoevsky, is a deep, and often dark, read, and if you argue that the depth is out of scope for our research into AI in Education and Learning Science, then perhaps you'd be right, but I would argue that such psychological depth is not only relevant but also necessary for an adequate exploration of these topics.
                                        <div class="annotation-author">Paul Marinos, Sep 26, 2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Educational Philosophy subtopic -->
            <div id="educational-philosophy" style="display: none;">
                <div class="topic-page-header">
                    <h1>Educational Philosophy</h1>
                    <p>Philosophical foundations of education, purpose, measurement, and teacher agency.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="educational-philosophy,risk,pedagogy,creativity">
                            <div class="bib-citation"
                                data-source-url="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=auiOrHcAAAAJ&citation_for_view=auiOrHcAAAAJ:ldfaerwXgEUC"
                                data-source-title="Beautiful risk of Education">
                                Biesta, G. (2015). "Beautiful risk of Education."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="biesta2015a-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This is a book about what many teachers know but are increasingly being prevented from talking about: that real education always involves a risk. The risk is there because, as WB Yeats has put it, education is not about filling a bucket but about lighting a fire. It is there because students are not to be seen as objects to be moulded and disciplined, but as subjects of action and responsibility. The Beautiful Risk of Education is organised around a critical discussion of seven key educational concepts: creativity, communication, teaching, learning, emancipation, democracy, and virtuosity. By opposing the risk aversion that characterises many contemporary educational policies and practices, Gert JJ Biesta makes a strong argument for giving risk a central place in our educational endeavours and brings risk taking to the forefront of a critical pedagogical practice.
                                        <div class="annotation-author">Paul Marinos 10/18/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="educational-philosophy,measurement,purpose,democracy">
                            <div class="bib-citation"
                                data-source-url="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=auiOrHcAAAAJ&citation_for_view=auiOrHcAAAAJ:IjCSPb-OGe4C"
                                data-source-title="Good education in an age of measurement: Ethics, politics, democracy">
                                Biesta, G. (2015). "Good education in an age of measurement: Ethics, politics, democracy."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="biesta2015b-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The widespread use of the measurement of educational outcomes in order to compare the performance of education within and across countries seems to express a real concern for the quality of education. This book argues that the focus on the measurement of educational outcomes has actually displaced questions about educational purpose. Biesta explores why the question as to what constitutes good education has become so much more difficult to ask and shows why this has been detrimental for the quality of education and for the level of democratic control over education. He provides concrete suggestions for engaging with the question of purpose in education in a new, more precise and more encompassing way, with explicit attention to the ethical, political and democratic dimensions of education.
                                        <div class="annotation-author">Paul Marinos 10/18/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="teacher-agency,beliefs,educational-reform,professionalism">
                            <div class="bib-citation"
                                data-source-url="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=auiOrHcAAAAJ&citation_for_view=auiOrHcAAAAJ:rHJHxKgnXwkC"
                                data-source-title="The role of beliefs in teacher agency">
                                Biesta, G., Priestley, M., & Robinson, S. (2015). "The role of beliefs in teacher agency."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="biesta2015c-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        There is an ongoing tension within educational policy worldwide between countries that seek to reduce the opportunities for teachers to exert judgement and control over their own work, and those who seek to promote it. Some see teacher agency as a weakness within the operation of schools and seek to replace it with evidence-based and data-driven approaches, whereas others argue that because of the complexities of situated educational practices, teacher agency is an indispensable element of good and meaningful education. In this paper, the authors draw from a two-year study into teacher agency against the backdrop of large-scale educational reform – the implementation of Scotland's Curriculum for Excellence.
                                        <div class="annotation-author">Paul Marinos 10/18/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="philosophy,Kant,enlightenment,critical-thinking,AI-education">
                            <div class="bib-citation"
                                data-source-url="https://jceps.com/index.php/jceps/article/view/638"
                                data-source-title="Have Courage to Use your Own Mind, with or without AI: The Relevance of Kant's Enlightenment to Higher Education in the Age of Artificial Intelligence">
                                Watanabe, A. (2024). "Have Courage to Use your Own Mind, with or without AI: The Relevance of Kant's Enlightenment to Higher Education in the Age of Artificial Intelligence." <em>Journal of Critical Education Policy Studies</em>. Vol. 22 No. 2 (2024): Special Issue: Artificial Intelligence (AI) in Education Part 1. 2024, 46-58.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="watanabe2024-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        This article explores the relevance of Kant's concept of Enlightenment to higher education in the age of AI, arguing that students must have the courage to use their own minds critically, with or without AI assistance.
                                        <div class="annotation-author">Elan Hebert</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- AI/ML Foundations subtopic -->
            <div id="ai-ml-foundations" style="display: none;">
                <div class="topic-page-header">
                    <h1>AI/ML Foundations</h1>
                    <p>Technical foundations of AI and machine learning relevant to education.</p>
                </div>
                <div class="topic-content">
                    <div class="bibliography-container">
                        <div class="bib-entry" data-tags="GPT,language-models,pre-training,transformers,OpenAI">
                            <div class="bib-citation"
                                data-source-url="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
                                data-source-title="Improving language understanding by generative pre-training">
                                Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). "Improving language understanding by generative pre-training." <em>OpenAI</em>.
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="radford2018-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper addresses key challenges in natural language understanding. The study demonstrates that significant improvements can be achieved by first pre-training a language model on a large, diverse corpus of unlabeled text, then fine-tuning it discriminatively for each specific task. The Transformer architecture is chosen for its ability to handle long-term dependencies more effectively than recurrent networks. For unsupervised pre-training, the model uses the BooksCorpus dataset, consisting of 700 unpublished books across genres such as adventure, romance, and fantasy (about 1 billion words in total), enabling the model to capture long-range context. The study highlights that generative pre-training combined with discriminative fine-tuning is a powerful method for advancing natural language understanding, setting the foundation for modern pre-trained language models.
                                        <div class="annotation-author">Dan Ahimbisibwe 10/09/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>

                        <div class="bib-entry" data-tags="AI-policy,ethics,education-policy,AIED">
                            <div class="bib-citation"
                                data-source-url="https://doi.org/10.1007/s40593-020-00216-z"
                                data-source-title="Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies">
                                Schiff, D. (2025). "Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies."
                                <span class="collapse-indicator"></span>
                            </div>
                            <div class="bib-annotation-container" id="schiff2025-annotation">
                                <div class="bib-annotation">
                                    <div class="annotation-text">
                                        The paper analyzes 24 national AI policy strategies to explore the role education plays in policymaking, stating that the strategies focus more on "education for AI" rather than "AI for education" (AIED). This means that the strategies mainly emphasize on preparing a workforce skilled in AI technologies through training AI experts, reskilling workers, and promoting public AI literacy, but lack discussions about the ethical and social implications of AI applied within educational settings. The author argues for bridging the current policy gap by encouraging policymakers to integrate ethical considerations explicitly into the design, deployment, and governance of AI in education. This article pushes for a dual approach of investing in human capital for AI and harnessing AI responsively to improve education itself.
                                        <div class="annotation-author">Nasrin Alanna Aidi 10/23/2025</div>
                                    </div>
                                </div>
                                <div class="annotation-actions">
                                    <button class="bib-button" onclick="viewSource(this)">View Source</button>
                                    <button class="add-perspective-btn">Add Your Perspective</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Team Members Page -->
            <div id="team-members" style="display: none;">
                <div class="topic-page-header">
                    <h1>Our Team</h1>
                    <p>Our VIP team is composed of dedicated students and faculty contributing to AI in Education research.</p>
                </div>
                <div class="topic-content">
                    <div id="team-members-list" style="max-width: 800px; margin: 0 auto;">
                        <!-- Content will be populated by JavaScript -->
                    </div>
                </div>
            </div>

            <!-- Contributor Pages will be dynamically generated -->
        </div>
    </main>

    <div class="source-modal" id="sourceModal">
        <div class="source-modal-content">
            <div class="source-modal-header">
                <div class="source-modal-title" id="modalTitle">Source Title</div>
                <button class="close-modal" onclick="closeSourceModal()">&times;</button>
            </div>
            <div class="source-iframe-container">
                <iframe class="source-iframe" id="sourceIframe" src=""></iframe>
            </div>
        </div>
    </div>

    <footer class="site-footer">
        <div class="container">
            <div class="footer-grid">
               
                
                <div class="footer-column">
                    <h3>About the Team</h3>
                    <ul class="footer-links">
                        <li><a href="https://as.nyu.edu/faculty/alexander-landfair.html" target="_blank">Faculty Advisor: Alexander Landfair</a></li>
                        <li><a href="#" onclick="showTopicPage('team-members'); return false;">Our Team</a></li>
                        <li><a href="https://engineering.nyu.edu/vip-team/ai-education-1" target="_blank">Ongoing Projects</a></li>
                        <li><a href="https://engineering.nyu.edu/vip-team/ai-education-1" target="_blank">Application Process</a></li>
                    </ul>
                </div>
                
                <div class="footer-column">
                    <h3>Partners & Resources</h3>
                    <ul class="footer-links">
                        <li><a href="https://cas.nyu.edu/ewp.html" target="_blank">NYU Expository Writing Program</a></li>
                        <li><a href="https://cas.nyu.edu/ewp/writing-center.html" target="_blank">NYU Writing Center</a></li>
                        <li><a href="https://engineering.nyu.edu/research-innovation/student-research/vertically-integrated-projects" target="_blank">Tandon VIP Program</a></li>                        <li><a href="#">Academic Support</a></li>
                    </ul>
                </div>
            </div>
            
            <div class="footer-bottom">
                <p>&copy; 2025 AI in Education VIP Team | NYU Tandon School of Engineering | Professor Alexander Landfair</p>
            </div>
        </div>
    </footer>

    <div class="popup" id="contribute-popup">
        <div class="popup-content">
            <span class="close-btn" onclick="closePopup()">&times;</span>
            <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeORMy6rhVbfiJy9oDd_8H13_Br2nAo6AyX45LjN3GNFGVN7A/viewform?embedded=true" width="100%" height="100%" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
        </div>
    </div>

    <script>
        // All the JavaScript functionality from the original site, adapted for AI in Education
        function populateTeamMembersList() {
            // Map contributor IDs to display names
            const contributorNames = {
                'alexander-landfair': 'Alexander Landfair',
                'cate-hackett': 'Cate Hackett',
                'dan-ahimbisibwe': 'Dan Ahimbisibwe',
                'debika-dharma-lingam': 'Debika Dharma Lingam',
                'elan-hebert': 'Elan Hebert',
                'ethan-lu': 'Ethan Lu',
                'jesse-noppe-brandon': 'Jesse Noppe-Brandon',
                'joseph-jiminian': 'Joseph Jiminian',
                'josephine-li': 'Josephine Li',
                'karen-maza-delgado': 'Karen Maza Delgado',
                'meiling-zhang': 'Meiling Zhang',
                'muhammad-farhan': 'Muhammad Farhan',
                'nasrin-alanna-aidi': 'Nasrin Alanna Aidi',
                'paul-marinos': 'Paul Marinos',
                'rohan-kapur': 'Rohan Kapur',
                'sabria-islam': 'Sabria Islam',
                'srinivas-harish': 'Srinivas Harish',
                'unmesh-achar': 'Unmesh Achar',
                'yanze-wu': 'Yanze Wu',
                'yufei-huang': 'Yufei Huang'
            };

            // Count contributions for each team member
            const contributionCounts = {};

            // Initialize counts
            Object.values(contributorNames).forEach(name => {
                contributionCounts[name] = 0;
            });

            // Count unique citations for each contributor (matching what's displayed on their page)
            Object.entries(contributorNames).forEach(([id, name]) => {
                const allAnnotations = document.querySelectorAll('.bib-annotation');
                const processedEntries = new Set();

                allAnnotations.forEach(annotation => {
                    const authorDiv = annotation.querySelector('.annotation-author');
                    if (authorDiv && authorDiv.textContent.includes(name)) {
                        const bibEntry = annotation.closest('.bib-entry');
                        if (bibEntry) {
                            // Use citation text to identify unique entries
                            const citationText = bibEntry.querySelector('.bib-citation')?.textContent || '';
                            const entryKey = citationText.substring(0, 100);

                            // Only count each unique citation once
                            if (!processedEntries.has(entryKey)) {
                                processedEntries.add(entryKey);
                                contributionCounts[name]++;
                            }
                        }
                    }
                });
            });

            // Create array of contributors with their counts
            const contributors = Object.entries(contributorNames).map(([id, name]) => ({
                id: id,
                name: name,
                count: contributionCounts[name],
                isFaculty: id === 'alexander-landfair'
            }));

            // Separate faculty and students, sort students by contribution count
            const faculty = contributors.filter(c => c.isFaculty);
            const students = contributors.filter(c => !c.isFaculty)
                .sort((a, b) => b.count - a.count); // Sort descending by count

            // Build the HTML
            const container = document.getElementById('team-members-list');
            if (!container) return;

            let html = '';

            // Faculty section
            html += '<h2 style="color: #57068c; margin-top: 30px; margin-bottom: 20px;">Faculty Advisor</h2>';
            html += '<ul style="list-style: none; padding-left: 0; line-height: 2;">';
            faculty.forEach(contributor => {
                html += `
                    <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
                        <a href="#" onclick="showContributorPage('${contributor.id}'); return false;" style="color: #57068c; text-decoration: none;">
                            <strong>${contributor.name}</strong>
                        </a>
                        <span style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.85em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">
                            ${contributor.count}
                        </span>
                        <span style="color: #666;"> - Faculty Advisor, NYU Expository Writing Program</span>
                    </li>
                `;
            });
            html += '</ul>';

            // Student section
            html += '<h2 style="color: #57068c; margin-top: 40px; margin-bottom: 20px;">Student Research Contributors</h2>';
            html += '<ul style="list-style: none; padding-left: 0; line-height: 2;">';
            students.forEach(contributor => {
                html += `
                    <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
                        <a href="#" onclick="showContributorPage('${contributor.id}'); return false;" style="color: #333; text-decoration: none;">
                            ${contributor.name}
                        </a>
                        <span style="background-color: #f0e6f6; color: #57068c; padding: 2px 8px; border-radius: 10px; font-size: 0.85em; font-weight: 600; margin-left: 8px; display: inline-block; min-width: 24px; text-align: center;">
                            ${contributor.count}
                        </span>
                    </li>
                `;
            });
            html += '</ul>';

            // Footer
            html += `
                <p style="margin-top: 30px; color: #666; font-style: italic;">
                    Interested in joining our team? Visit our <a href="https://engineering.nyu.edu/vip-team/ai-education-1" target="_blank" style="color: #57068c;">VIP program page</a> to learn about the application process.
                </p>
            `;

            container.innerHTML = html;
        }

        function updateSourceCounts() {
            // Count sources for each section and update the count badges
            const countElements = document.querySelectorAll('[data-count-target]');

            countElements.forEach(countEl => {
                const targetId = countEl.getAttribute('data-count-target');
                const targetSection = document.getElementById(targetId);

                if (targetSection) {
                    let count = 0;

                    // Check if this section has subtopic cards (it's a parent section)
                    const subtopicCards = targetSection.querySelectorAll('.subtopic-card');

                    if (subtopicCards.length > 0) {
                        // This is a parent section - sum entries from all subtopics
                        subtopicCards.forEach(card => {
                            const onclick = card.getAttribute('onclick');
                            if (onclick) {
                                // Extract subtopic ID from onclick handler
                                const match = onclick.match(/showSubtopicPage\([^,]+,\s*'([^']+)'\)|showTopicPage\('([^']+)'\)/);
                                if (match) {
                                    const subtopicId = match[1] || match[2];
                                    const subtopicSection = document.getElementById(subtopicId);
                                    if (subtopicSection) {
                                        const subtopicEntries = subtopicSection.querySelectorAll('.bib-entry');
                                        count += subtopicEntries.length;
                                    }
                                }
                            }
                        });
                    } else {
                        // This is a leaf section - count direct bib-entry elements
                        const bibEntries = targetSection.querySelectorAll('.bib-entry');
                        count = bibEntries.length;
                    }

                    countEl.textContent = count;
                } else {
                    countEl.textContent = '0';
                }
            });
        }

        document.addEventListener('DOMContentLoaded', function() {
            initializeNavigationState();
            initializeSearch();
            initializePathwayNavigation();
            initializePopupSystem();
            initializeAnnotations();
            initializeFilteringSystem();
            updateEntryCounter();
            populateTeamMembersList();
            updateSourceCounts();
            logDebugInfo();
        });

        window.addEventListener('load', function() {
            updateEntryCounter();
            setupImprovedPathwayNavigation();
            initializeHeaderEffects();
        });

        let navigationState = {
            currentView: 'landing',
            topicId: null,
            subtopicId: null,
            subsubtopicId: null,
            pathwayName: null,
            filterTag: null
        };

        const knownTopics = [
            'evaluating-tools',
            'understanding-users',
            'assessing-impacts',
            'innovating-edtech',
            'learning-science',
            'research-methods'
        ];

        const knownSubtopics = [
            // Evaluating Tools subtopics
            'coding',
            'creativity',
            'detection-tools',
            'ethics-safety',
            'equity-social-justice',
            'error-hallucination',
            'reasoning',
            'usability',
            'translation',
            'tutoring-instruction',

            // Understanding Users subtopics
            'general',
            'administrators',
            'students',
            'faculty',

            // Assessing Impacts subtopics
            'learning-outcomes',
            'academic-integrity',
            'assessment-validity',
            'student-wellbeing',
            'equity-access',

            // Innovating EdTech subtopics
            'ai-tutoring',
            'writing-content-generation',
            'detection-integrity',
            'organizational-productivity',
            'feedback-assessment',
            'accessibility-inclusion',
            'learning-analytics',
            'scheduling',

            // Learning Science subtopics
            'writing-composition',
            'cognitive-science',
            'reading-literacy',
            'educational-philosophy',
            'ai-ml-foundations',

            // Research Methods & Resources subtopics
            'literature-review',
            'collaborative-research',
            'experimental-design',
            'survey-design',
            'interview-focus-groups',
            'data-analysis',
            'research-ethics',
            'academic-writing',

            // Legacy subtopics (for backward compatibility)
            'student-attitudes',
            'faculty-perspectives',
            'administrator-views',
            'ai-competencies',
            'ai-detection',
            'genai-capabilities',
            'tool-limitations',
            'comparative-analysis',
            'prototype-development',
            'user-testing',
            'integration-strategies',
            'scalability-assessment'
        ];

        function parseURLAndNavigate() {
            const urlParams = new URLSearchParams(window.location.search);
            const topic = urlParams.get('topic');
            const subtopic = urlParams.get('subtopic');
            const contributor = urlParams.get('contributor');

            if (contributor) {
                // Show contributor page
                showContributorPage(contributor, true);
            } else if (subtopic && topic) {
                // Show subtopic page
                showSubtopicPage(topic, subtopic, true);
            } else if (topic) {
                // Show topic page
                showTopicPage(topic, true);
            } else {
                // Show landing page
                showLandingPage(true);
            }
        }

        function initializeNavigationState() {
            // Parse URL on initial load
            parseURLAndNavigate();

            // Handle browser back/forward buttons
            window.addEventListener('popstate', function(event) {
                if (event.state) {
                    // Navigate based on stored state
                    if (event.state.currentView === 'contributor') {
                        showContributorPage(event.state.contributorId, true);
                    } else if (event.state.currentView === 'subtopic') {
                        showSubtopicPage(event.state.topicId, event.state.subtopicId, true);
                    } else if (event.state.currentView === 'topic') {
                        showTopicPage(event.state.topicId, true);
                    } else {
                        showLandingPage(true);
                    }
                } else {
                    // If no state, parse URL
                    parseURLAndNavigate();
                }
            });
        }

        function initializeHeaderEffects() {
            const headerTitle = document.querySelector('.header-title');
            
            if (!headerTitle) return;
            
            const scrollThreshold = 150;
            
            function updateTitleVisibility() {
                const scrollPosition = window.scrollY || window.pageYOffset;
                
                if (scrollPosition >= scrollThreshold) {
                    headerTitle.classList.add('visible');
                } else {
                    headerTitle.classList.remove('visible');
                }
            }
            
            window.addEventListener('scroll', updateTitleVisibility);
            updateTitleVisibility();
        }

        function updateBreadcrumbs() {
            const breadcrumbs = document.querySelector('.breadcrumbs');
            if (!breadcrumbs) return;

            let breadcrumbsHTML = `<a href="${window.location.pathname}" data-nav="home">Home</a>`;

            switch (navigationState.currentView) {
                case 'landing':
                    break;

                case 'topic':
                    const topicElement = document.getElementById(navigationState.topicId);
                    const topicName = topicElement ? topicElement.querySelector('.topic-page-header h1').textContent : 'Topic';
                    breadcrumbsHTML += `
                        <span class="separator">›</span>
                        <span class="current">${topicName}</span>
                    `;
                    break;

                case 'subtopic':
                    const topicElem = document.getElementById(navigationState.topicId);
                    const subtopicElem = document.getElementById(navigationState.subtopicId);

                    const topicTitle = topicElem ? topicElem.querySelector('.topic-page-header h1').textContent : 'Topic';
                    const subtopicTitle = subtopicElem ? subtopicElem.querySelector('.topic-page-header h1').textContent : 'Subtopic';

                    breadcrumbsHTML += `
                        <span class="separator">›</span>
                        <a href="${window.location.pathname}?topic=${navigationState.topicId}" data-nav="topic" data-topic="${navigationState.topicId}">${topicTitle}</a>
                        <span class="separator">›</span>
                        <span class="current">${subtopicTitle}</span>
                    `;
                    break;

                case 'pathway':
                    breadcrumbsHTML += `
                        <span class="separator">›</span>
                        <span class="current">Research Path: ${navigationState.pathwayName}</span>
                    `;
                    break;

                case 'filtered':
                    breadcrumbsHTML += `
                        <span class="separator">›</span>
                        <span class="current">Research Path: ${navigationState.filterTag.split('-').map(word => word.charAt(0).toUpperCase() + word.slice(1)).join(' ')}</span>
                    `;
                    break;

                case 'contributor':
                    const contributorNames = {
                        'alexander-landfair': 'Alexander Landfair',
                        'cate-hackett': 'Cate Hackett',
                        'dan-ahimbisibwe': 'Dan Ahimbisibwe',
                        'debika-dharma-lingam': 'Debika Dharma Lingam',
                        'elan-hebert': 'Elan Hebert',
                        'ethan-lu': 'Ethan Lu',
                        'jesse-noppe-brandon': 'Jesse Noppe-Brandon',
                        'jiawen-li': 'Jiawen Li',
                        'joseph-jiminian': 'Joseph Jiminian',
                        'josephine-li': 'Josephine Li',
                        'karen-maza-delgado': 'Karen Maza Delgado',
                        'meiling-zhang': 'Meiling Zhang',
                        'muhammad-farhan': 'Muhammad Farhan',
                        'nasrin-alanna-aidi': 'Nasrin Alanna Aidi',
                        'paul-marinos': 'Paul Marinos',
                        'rohan-kapur': 'Rohan Kapur',
                        'sabria-islam': 'Sabria Islam',
                        'srinivas-harish': 'Srinivas Harish',
                        'unmesh-achar': 'Unmesh Achar',
                        'yanze-wu': 'Yanze Wu',
                        'yufei-huang': 'Yufei Huang'
                    };
                    const contributorName = contributorNames[navigationState.contributorId] || 'Contributor';
                    breadcrumbsHTML += `
                        <span class="separator">›</span>
                        <a href="#" onclick="showTopicPage('team-members'); return false;" data-nav="team-members">Team Members</a>
                        <span class="separator">›</span>
                        <span class="current">${contributorName}</span>
                    `;
                    break;
            }

            breadcrumbs.innerHTML = breadcrumbsHTML;

            // Add click handlers to breadcrumb links
            breadcrumbs.querySelectorAll('a[data-nav]').forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const navType = this.getAttribute('data-nav');
                    if (navType === 'home') {
                        showLandingPage();
                    } else if (navType === 'topic') {
                        const topicId = this.getAttribute('data-topic');
                        showTopicPage(topicId);
                    }
                });
            });
        }

        function setupImprovedPathwayNavigation() {
            const container = document.querySelector('.pathways-container');
            const cards = container.querySelectorAll('.pathway-card');
            
            if (!container || cards.length === 0) return;
            
            const cardWidth = cards[0].offsetWidth;
            const gapWidth = parseInt(window.getComputedStyle(container).getPropertyValue('gap')) || 20;
            const containerWidth = container.clientWidth;
            
            const visibleCards = Math.floor(containerWidth / (cardWidth + gapWidth));
            
            const prevBtn = document.querySelector('.pathway-nav.prev');
            const nextBtn = document.querySelector('.pathway-nav.next');
            
            if (prevBtn && nextBtn) {
                const scrollAmount = visibleCards * (cardWidth + gapWidth);
                
                prevBtn.onclick = function() {
                    if (container.scrollLeft < scrollAmount/2) {
                        const maxScroll = container.scrollWidth - containerWidth;
                        container.scrollTo({ 
                            left: maxScroll, 
                            behavior: 'smooth' 
                        });
                    } else {
                        container.scrollBy({ 
                            left: -scrollAmount, 
                            behavior: 'smooth' 
                        });
                    }
                };
                
                nextBtn.onclick = function() {
                    const maxScroll = container.scrollWidth - containerWidth;
                    if (container.scrollLeft > maxScroll - scrollAmount/2) {
                        container.scrollTo({ 
                            left: 0, 
                            behavior: 'smooth' 
                        });
                    } else {
                        container.scrollBy({ 
                            left: scrollAmount, 
                            behavior: 'smooth' 
                        });
                    }
                };
            }
            
            container.style.scrollSnapType = 'x proximity';
            container.querySelectorAll('.pathway-card').forEach(card => {
                card.style.scrollSnapAlign = 'start';
            });
        }

        function initializeSearch() {
            const headerSearch = document.getElementById('header-search');
            const headerSearchResults = document.getElementById('header-search-results');
            const heroSearch = document.getElementById('hero-search');
            const heroSearchResults = document.getElementById('hero-search-results');
            
            if (headerSearch && headerSearchResults) {
                headerSearch.addEventListener('input', function() {
                    const query = this.value.trim();
                    if (query.length >= 2) {
                        const results = performSearch(query);
                        displaySearchResults(results, headerSearchResults, headerSearch);
                    } else {
                        headerSearchResults.style.display = 'none';
                    }
                });
                
                headerSearch.addEventListener('focus', function() {
                    if (this.value.trim().length >= 2) {
                        const results = performSearch(this.value.trim());
                        displaySearchResults(results, headerSearchResults, headerSearch);
                    }
                });
            }
            
            if (heroSearch && heroSearchResults) {
                heroSearch.addEventListener('input', function() {
                    const query = this.value.trim();
                    if (query.length >= 2) {
                        const results = performSearch(query);
                        displaySearchResults(results, heroSearchResults, heroSearch);
                    } else {
                        heroSearchResults.style.display = 'none';
                    }
                });
                
                heroSearch.addEventListener('focus', function() {
                    if (this.value.trim().length >= 2) {
                        const results = performSearch(this.value.trim());
                        displaySearchResults(results, heroSearchResults, heroSearch);
                    }
                });
            }
            
            document.addEventListener('click', function(e) {
                if (!e.target.closest('.search-container')) {
                    if (headerSearchResults) headerSearchResults.style.display = 'none';
                    if (heroSearchResults) heroSearchResults.style.display = 'none';
                }
            });
        }

        function performSearch(query) {
            if (!query || query.length < 2) return [];
            
            query = query.toLowerCase();
            const results = [];
            
            // Search in topic titles
            document.querySelectorAll('.topic-page-header h1').forEach(topicHeader => {
                const topicName = topicHeader.textContent;
                const topicContainer = topicHeader.closest('[id]');
                if (!topicContainer) return;
                
                const topicId = topicContainer.id;
                
                if (topicName.toLowerCase().includes(query)) {
                    results.push({
                        type: 'topic',
                        id: topicId,
                        title: topicName,
                        context: 'Topic'
                    });
                }
            });
            
            // Search in subtopic titles
            document.querySelectorAll('.subtopic-card h3').forEach(subtopicHeader => {
                const subtopicName = subtopicHeader.textContent;
                const subtopicCard = subtopicHeader.closest('.subtopic-card');
                if (!subtopicCard) return;
                
                const topicContainer = subtopicCard.closest('[id]');
                if (!topicContainer) return;
                
                if (subtopicName.toLowerCase().includes(query)) {
                    const onclickAttr = subtopicCard.getAttribute('onclick');
                    if (onclickAttr) {
                        const match = onclickAttr.match(/showSubtopicPage\('([^']+)',\s*'([^']+)'\)/);
                        if (match) {
                            const topicId = match[1];
                            const subtopicId = match[2];
                            
                            results.push({
                                type: 'subtopic',
                                topicId: topicId,
                                subtopicId: subtopicId,
                                title: subtopicName,
                                context: `Subtopic in ${topicContainer.querySelector('h1')?.textContent || 'Topic'}`
                            });
                        }
                    }
                }
            });

            // Search in citations
            document.querySelectorAll('.bib-citation').forEach(citation => {
                const citationText = citation.textContent.trim();
                
                if (citationText.toLowerCase().includes(query)) {
                    const bibEntry = citation.closest('.bib-entry');
                    if (!bibEntry) return;
                    
                    let currentNode = citation;
                    let containerId = null;
                    
                    while (currentNode && !containerId) {
                        currentNode = currentNode.parentElement;
                        if (!currentNode) break;
                        
                        if (currentNode.id) {
                            if (knownTopics.includes(currentNode.id) || 
                                knownSubtopics.includes(currentNode.id)) {
                                containerId = currentNode.id;
                                break;
                            }
                        }
                    }
                    
                    if (containerId) {
                        const containerElement = document.getElementById(containerId);
                        const headerText = containerElement ? 
                            containerElement.querySelector('.topic-page-header h1')?.textContent || 'Topic' : 
                            'Topic';
                        
                        results.push({
                            type: 'citation',
                            element: citation,
                            bibEntry: bibEntry,
                            topicId: containerId,
                            title: citationText.length > 60 ? citationText.substring(0, 60) + '...' : citationText,
                            context: `Citation in ${headerText}`
                        });
                    }
                }
            });

            // Search in annotation authors (contributors)
            document.querySelectorAll('.annotation-author').forEach(authorDiv => {
                const authorText = authorDiv.textContent.trim();

                if (authorText.toLowerCase().includes(query)) {
                    const annotation = authorDiv.closest('.bib-annotation');
                    if (!annotation) return;

                    const bibEntry = annotation.closest('.bib-entry');
                    if (!bibEntry) return;

                    const citation = bibEntry.querySelector('.bib-citation');
                    if (!citation) return;

                    const citationText = citation.textContent.trim();

                    let currentNode = annotation;
                    let containerId = null;

                    while (currentNode && !containerId) {
                        currentNode = currentNode.parentElement;
                        if (!currentNode) break;

                        if (currentNode.id) {
                            if (knownTopics.includes(currentNode.id) ||
                                knownSubtopics.includes(currentNode.id)) {
                                containerId = currentNode.id;
                                break;
                            }
                        }
                    }

                    if (containerId) {
                        const containerElement = document.getElementById(containerId);
                        const headerText = containerElement ?
                            containerElement.querySelector('.topic-page-header h1')?.textContent || 'Topic' :
                            'Topic';

                        results.push({
                            type: 'contributor',
                            element: citation,
                            bibEntry: bibEntry,
                            topicId: containerId,
                            title: citationText.length > 60 ? citationText.substring(0, 60) + '...' : citationText,
                            context: `Annotated by ${authorText} in ${headerText}`
                        });
                    }
                }
            });

            return results;
        }

        function displaySearchResults(results, resultsContainer, inputElement) {
            resultsContainer.innerHTML = '';
            
            if (results.length === 0) {
                resultsContainer.innerHTML = '<div class="search-result-item">No results found</div>';
                resultsContainer.style.display = 'block';
                return;
            }
            
            results.forEach(result => {
                const resultItem = document.createElement('div');
                resultItem.className = 'search-result-item';
                
                const title = document.createElement('div');
                title.className = 'result-title';
                title.textContent = result.title;
                
                const context = document.createElement('div');
                context.className = 'result-context';
                context.textContent = result.context;
                
                resultItem.appendChild(title);
                resultItem.appendChild(context);
                
                resultItem.addEventListener('click', () => {
                    resultsContainer.style.display = 'none';

                    if (result.type === 'topic') {
                        showTopicPage(result.id);
                    }
                    else if (result.type === 'subtopic') {
                        showSubtopicPage(result.topicId, result.subtopicId);
                    }
                    else if (result.type === 'citation' || result.type === 'contributor') {
                        showTopicPage(result.topicId);

                        setTimeout(() => {
                            if (result.element) {
                                result.element.scrollIntoView({ behavior: 'smooth', block: 'center' });
                                result.element.classList.add('highlight');
                                setTimeout(() => {
                                    result.element.classList.remove('highlight');
                                }, 2000);
                            }
                        }, 300);
                    }
                });
                
                resultsContainer.appendChild(resultItem);
            });
            
            resultsContainer.style.display = 'block';
        }

        function showLandingPage(skipHistory) {
            navigationState = {
                currentView: 'landing',
                topicId: null,
                subtopicId: null,
                subsubtopicId: null,
                pathwayName: null,
                filterTag: null
            };

            document.querySelectorAll('.topic-pages > div').forEach(page => {
                page.style.display = 'none';
            });

            document.querySelector('.topic-pages').style.display = 'none';
            document.querySelector('.landing-page').style.display = 'block';

            document.body.classList.remove('show-topics', 'show-breadcrumbs');

            document.querySelector('.header-title').classList.remove('visible');

            const filteredResults = document.getElementById('filtered-results');
            if (filteredResults) {
                filteredResults.style.display = 'none';
            }

            // Update browser URL using History API
            if (!skipHistory) {
                const url = window.location.pathname;
                history.pushState(navigationState, 'AI in Education VIP Research Exchange', url);
            }

            window.scrollTo(0, 0);
            updateEntryCounter();
        }

        function showTopicPage(topicId, skipHistory) {
            navigationState = {
                currentView: 'topic',
                topicId: topicId,
                subtopicId: null,
                subsubtopicId: null,
                pathwayName: null,
                filterTag: null
            };

            document.body.classList.add('show-topics');
            document.body.classList.add('show-breadcrumbs');

            document.querySelectorAll('.topic-pages > div').forEach(div => {
                div.style.display = 'none';
            });

            document.getElementById(topicId).style.display = 'block';

            document.querySelector('.landing-page').style.display = 'none';
            document.querySelector('.topic-pages').style.display = 'block';

            const headerTitle = document.querySelector('.header-title');
            headerTitle.textContent = '';
            headerTitle.classList.add('visible');

            // Update browser URL using History API
            if (!skipHistory) {
                const url = `${window.location.pathname}?topic=${topicId}`;
                const topicElement = document.getElementById(topicId);
                const pageTitle = topicElement ? topicElement.querySelector('.topic-page-header h1').textContent : 'Topic';
                history.pushState(navigationState, pageTitle, url);
            }

            updateBreadcrumbs();
            window.scrollTo(0, 0);
        }

        function showSubtopicPage(topicId, subtopicId, skipHistory) {
            navigationState = {
                currentView: 'subtopic',
                topicId: topicId,
                subtopicId: subtopicId,
                subsubtopicId: null,
                pathwayName: null,
                filterTag: null
            };

            document.body.classList.add('show-topics');
            document.body.classList.add('show-breadcrumbs');

            document.querySelectorAll('.topic-pages > div').forEach(div => {
                div.style.display = 'none';
            });

            document.getElementById(subtopicId).style.display = 'block';

            document.querySelector('.landing-page').style.display = 'none';
            document.querySelector('.topic-pages').style.display = 'block';

            const headerTitle = document.querySelector('.header-title');
            headerTitle.textContent = '';
            headerTitle.classList.add('visible');

            // Update browser URL using History API
            if (!skipHistory) {
                const url = `${window.location.pathname}?topic=${topicId}&subtopic=${subtopicId}`;
                const subtopicElement = document.getElementById(subtopicId);
                const pageTitle = subtopicElement ? subtopicElement.querySelector('.topic-page-header h1').textContent : 'Subtopic';
                history.pushState(navigationState, pageTitle, url);
            }

            updateBreadcrumbs();
            window.scrollTo(0, 0);
        }

        function showContributorPage(contributorId, skipHistory) {
            // Map contributor IDs to display names
            const contributorNames = {
                'alexander-landfair': 'Alexander Landfair',
                'cate-hackett': 'Cate Hackett',
                'dan-ahimbisibwe': 'Dan Ahimbisibwe',
                'debika-dharma-lingam': 'Debika Dharma Lingam',
                'elan-hebert': 'Elan Hebert',
                'ethan-lu': 'Ethan Lu',
                'jesse-noppe-brandon': 'Jesse Noppe-Brandon',
                'joseph-jiminian': 'Joseph Jiminian',
                'josephine-li': 'Josephine Li',
                'karen-maza-delgado': 'Karen Maza Delgado',
                'meiling-zhang': 'Meiling Zhang',
                'muhammad-farhan': 'Muhammad Farhan',
                'nasrin-alanna-aidi': 'Nasrin Alanna Aidi',
                'paul-marinos': 'Paul Marinos',
                'rohan-kapur': 'Rohan Kapur',
                'sabria-islam': 'Sabria Islam',
                'srinivas-harish': 'Srinivas Harish',
                'unmesh-achar': 'Unmesh Achar',
                'yanze-wu': 'Yanze Wu',
                'yufei-huang': 'Yufei Huang'
            };

            const contributorName = contributorNames[contributorId];

            // Find all annotations by this contributor
            const allAnnotations = document.querySelectorAll('.bib-annotation');
            const contributorAnnotations = [];
            const processedEntries = new Set();

            allAnnotations.forEach(annotation => {
                const authorDiv = annotation.querySelector('.annotation-author');
                if (authorDiv && authorDiv.textContent.includes(contributorName)) {
                    const bibEntry = annotation.closest('.bib-entry');
                    if (bibEntry) {
                        const citationText = bibEntry.querySelector('.bib-citation')?.textContent || '';
                        const entryKey = citationText.substring(0, 100);

                        if (!processedEntries.has(entryKey)) {
                            processedEntries.add(entryKey);

                            // Clone the entry
                            const clonedEntry = bibEntry.cloneNode(true);

                            // Keep the entire annotation thread intact for context
                            // (If contributor participated, show full discussion including replies/responses)

                            // Make IDs unique by prefixing with contributor ID
                            const annotationContainer = clonedEntry.querySelector('.bib-annotation-container');
                            if (annotationContainer && annotationContainer.id) {
                                const originalId = annotationContainer.id;
                                const newId = `${contributorId}-${originalId}`;
                                annotationContainer.id = newId;

                                // Hide initially
                                annotationContainer.style.display = 'none';
                            }

                            // Ensure collapse indicator is not expanded
                            const indicator = clonedEntry.querySelector('.collapse-indicator');
                            if (indicator) {
                                indicator.classList.remove('expanded');
                            }

                            contributorAnnotations.push({
                                entry: clonedEntry,
                                citation: clonedEntry.querySelector('.bib-citation')
                            });
                        }
                    }
                }
            });

            // Create or update contributor page
            let contributorPage = document.getElementById(`contributor-${contributorId}`);
            if (!contributorPage) {
                contributorPage = document.createElement('div');
                contributorPage.id = `contributor-${contributorId}`;
                contributorPage.style.display = 'none';
                document.querySelector('.topic-pages').appendChild(contributorPage);
            }

            // Clear existing content
            contributorPage.innerHTML = '';

            // Create page structure
            const pageHeader = document.createElement('div');
            pageHeader.className = 'topic-page-header';
            pageHeader.innerHTML = `
                <h1>${contributorName}</h1>
                <p>Contributions to the AI in Education VIP Research Exchange (${contributorAnnotations.length} ${contributorAnnotations.length === 1 ? 'annotation' : 'annotations'})</p>
            `;

            const topicContent = document.createElement('div');
            topicContent.className = 'topic-content';

            const bibliographyContainer = document.createElement('div');
            bibliographyContainer.className = 'bibliography-container';

            // Append each entry
            contributorAnnotations.forEach(item => {
                const entry = item.entry;

                // Make sure citation has pointer cursor
                const citation = entry.querySelector('.bib-citation');
                if (citation) {
                    citation.style.cursor = 'pointer';
                }

                bibliographyContainer.appendChild(entry);
            });

            // Use event delegation for click handling within this contributor page
            bibliographyContainer.addEventListener('click', function(event) {
                // Find if click was on or within a citation
                const citation = event.target.closest('.bib-citation');

                if (citation) {
                    // Don't toggle if clicking on links
                    if (event.target.closest('a')) {
                        return;
                    }

                    // Find the annotation container for this citation
                    const bibEntry = citation.closest('.bib-entry');
                    if (bibEntry) {
                        const annotationContainer = bibEntry.querySelector('.bib-annotation-container');
                        if (annotationContainer && annotationContainer.id) {
                            // Toggle within this contributor page
                            const isCurrentlyVisible = annotationContainer.style.display === 'block';

                            // Close all annotations in this contributor page
                            contributorPage.querySelectorAll('.bib-annotation-container').forEach(container => {
                                container.style.display = 'none';
                            });
                            contributorPage.querySelectorAll('.collapse-indicator').forEach(indicator => {
                                indicator.classList.remove('expanded');
                            });

                            // Open this annotation if it wasn't already open
                            if (!isCurrentlyVisible) {
                                annotationContainer.style.display = 'block';
                                annotationContainer.scrollIntoView({ behavior: 'smooth', block: 'nearest' });

                                // Find and rotate the indicator for this entry
                                const indicator = bibEntry.querySelector('.collapse-indicator');
                                if (indicator) {
                                    indicator.classList.add('expanded');
                                }
                            }
                        }
                    }
                }
            });

            topicContent.appendChild(bibliographyContainer);
            contributorPage.appendChild(pageHeader);
            contributorPage.appendChild(topicContent);

            // Show the page
            navigationState = {
                currentView: 'contributor',
                contributorId: contributorId,
                topicId: null,
                subtopicId: null,
                subsubtopicId: null,
                pathwayName: null,
                filterTag: null
            };

            document.body.classList.add('show-topics');
            document.body.classList.add('show-breadcrumbs');

            document.querySelectorAll('.topic-pages > div').forEach(div => {
                div.style.display = 'none';
            });

            contributorPage.style.display = 'block';

            document.querySelector('.landing-page').style.display = 'none';
            document.querySelector('.topic-pages').style.display = 'block';

            const headerTitle = document.querySelector('.header-title');
            headerTitle.textContent = '';
            headerTitle.classList.add('visible');

            // Update browser URL using History API
            if (!skipHistory) {
                const url = `${window.location.pathname}?contributor=${contributorId}`;
                history.pushState(navigationState, contributorName, url);
            }

            updateBreadcrumbs();
            window.scrollTo(0, 0);
        }

        function initializePathwayNavigation() {
            const pathwaysContainer = document.querySelector('.pathways-container');
            const prevBtn = document.querySelector('.pathway-nav.prev');
            const nextBtn = document.querySelector('.pathway-nav.next');
            
            if (pathwaysContainer && prevBtn && nextBtn) {
                prevBtn.addEventListener('click', function() {
                    pathwaysContainer.scrollBy({ left: -300, behavior: 'smooth' });
                });
                
                nextBtn.addEventListener('click', function() {
                    pathwaysContainer.scrollBy({ left: 300, behavior: 'smooth' });
                });
            }
            
            const pathwayCards = document.querySelectorAll('.pathway-card');
            pathwayCards.forEach((card, index) => {
                const viewMoreLink = card.querySelector('.view-more');
                if (viewMoreLink) {
                    viewMoreLink.href = '#';
                    viewMoreLink.addEventListener('click', function(e) {
                        e.preventDefault();
                        showPathwayPage(index + 1);
                    });
                }
            });
        }

        function showPathwayPage(pathwayId) {
            const pathwayElement = document.querySelector(`.pathway-card:nth-child(${pathwayId})`);
            const pathwayName = pathwayElement.querySelector('.pathway-title').textContent;
            
            navigationState = {
                currentView: 'pathway',
                topicId: null,
                subtopicId: null,
                subsubtopicId: null,
                pathwayName: pathwayName,
                filterTag: null
            };
            
            document.body.classList.add('show-topics');
            document.body.classList.add('show-breadcrumbs');
            
            let methodsContainer = document.getElementById('research-methods-placeholder');
            if (!methodsContainer) {
                methodsContainer = document.createElement('div');
                methodsContainer.id = 'research-methods-placeholder';
                methodsContainer.className = 'topic-container';
                document.querySelector('.topic-pages').appendChild(methodsContainer);
            }
            
            methodsContainer.innerHTML = `
                <div class="topic-page-header">
                    <h1>${pathwayName}</h1>
                    <p>Research methodology resources for this area are currently being developed.</p>
                </div>
                <div class="topic-content">
                    <div class="empty-content-placeholder">
                        <div class="placeholder-message">
                            <i class="fas fa-tools" style="font-size: 2.5rem; color: #57068c; margin-bottom: 15px;"></i>
                            <h3>Resources Coming Soon</h3>
                            <p>Our VIP team is developing comprehensive guides and resources for this research methodology. Check back soon for tutorials, templates, and best practices.</p>
                            <button class="contribute-btn" style="margin-top: 15px;" onclick="openContributePopup()">Contribute Resources</button>
                        </div>
                    </div>
                </div>
            `;
            
            document.querySelectorAll('.topic-pages > div').forEach(div => {
                div.style.display = 'none';
            });
            
            methodsContainer.style.display = 'block';
            
            document.querySelector('.landing-page').style.display = 'none';
            document.querySelector('.topic-pages').style.display = 'block';
            
            const headerTitle = document.querySelector('.header-title');
            headerTitle.textContent = '';
            headerTitle.classList.add('visible');
            
            updateBreadcrumbs();
            window.scrollTo(0, 0);
        }

        function initializePopupSystem() {
            const contributeBtn = document.querySelector('.contribute-btn');
            if (contributeBtn) {
                contributeBtn.addEventListener('click', openContributePopup);
            }
            
            const perspectiveButtons = document.querySelectorAll('.add-perspective-btn');
            perspectiveButtons.forEach(button => {
                button.addEventListener('click', openContributePopup);
            });
            
            const closeButtons = document.querySelectorAll('.close-btn');
            closeButtons.forEach(button => {
                button.addEventListener('click', closeContributePopup);
            });
            
            const popups = document.querySelectorAll('.popup');
            popups.forEach(popup => {
                popup.addEventListener('click', function(event) {
                    if (event.target === this) {
                        closeContributePopup();
                    }
                });
            });
            
            document.addEventListener('keydown', function(e) {
                if (e.key === 'Escape') {
                    closeContributePopup();
                }
            });
            
            const closeModalBtn = document.querySelector('.close-modal');
            if (closeModalBtn) {
                closeModalBtn.addEventListener('click', closeSourceModal);
            }
        }

        function openContributePopup() {
            document.getElementById('contribute-popup').style.display = 'flex';
            document.body.style.overflow = 'hidden';
        }

        function closeContributePopup() {
            document.getElementById('contribute-popup').style.display = 'none';
            document.body.style.overflow = 'auto';
        }

        function closePopup() {
            closeContributePopup();
        }

        function initializeAnnotations() {
            // Make bibliography entries clickable to toggle annotations
            document.querySelectorAll('.bib-entry').forEach(entry => {
                // Find the annotation container for this entry
                const annotationContainer = entry.querySelector('.bib-annotation-container');
                if (!annotationContainer) return;

                // Extract the entry ID from the annotation container ID (e.g., "sundar2020-annotation" -> "sundar2020")
                const entryId = annotationContainer.id.replace('-annotation', '');

                // Add click handler to the citation area
                const citation = entry.querySelector('.bib-citation');
                if (citation) {
                    citation.addEventListener('click', function(event) {
                        // Don't toggle if clicking on links
                        if (event.target.closest('a')) {
                            return;
                        }

                        toggleAnnotation(entryId);
                    });

                    // Add pointer cursor to indicate clickability
                    citation.style.cursor = 'pointer';
                }
            });
        }

        function toggleAnnotation(entryId) {
            const annotationContainer = document.getElementById(entryId + '-annotation');

            if (!annotationContainer) {
                console.error(`Annotation container not found for ID: ${entryId}-annotation`);
                return;
            }

            const isCurrentlyVisible = annotationContainer.style.display === 'block';

            // Close all annotations and reset all indicators
            document.querySelectorAll('.bib-annotation-container').forEach(container => {
                container.style.display = 'none';
            });
            document.querySelectorAll('.collapse-indicator').forEach(indicator => {
                indicator.classList.remove('expanded');
            });

            // Open this annotation if it wasn't already open
            if (!isCurrentlyVisible) {
                annotationContainer.style.display = 'block';
                annotationContainer.scrollIntoView({ behavior: 'smooth', block: 'nearest' });

                // Find and rotate the indicator for this entry
                const entry = annotationContainer.closest('.bib-entry');
                if (entry) {
                    const indicator = entry.querySelector('.collapse-indicator');
                    if (indicator) {
                        indicator.classList.add('expanded');
                    }
                }
            }
        }

        function viewSource(button) {
            const entry = button.closest('.bib-entry');
            const citation = entry.querySelector('.bib-citation');
            const sourceUrl = citation.getAttribute('data-source-url');
            window.open(sourceUrl, '_blank');
        }

        function closeSourceModal() {
            document.getElementById('sourceModal').style.display = 'none';
        }

        function initializeFilteringSystem() {
            document.querySelectorAll('.pathway-card .view-more').forEach(link => {
                const tag = link.getAttribute('data-tag');
                if (tag) {
                    link.addEventListener('click', function(e) {
                        e.preventDefault();
                        filterEntriesByTag(tag);
                    });
                }
            });
        }

        function filterEntriesByTag(tag) {
            navigationState = {
                currentView: 'filtered',
                topicId: null,
                subtopicId: null,
                subsubtopicId: null,
                pathwayName: null,
                filterTag: tag
            };
            
            document.body.classList.add('show-topics');
            document.body.classList.add('show-breadcrumbs');
            
            document.querySelectorAll('.topic-pages > div').forEach(div => {
                div.style.display = 'none';
            });
            
            let filteredContainer = document.getElementById('filtered-results');
            if (!filteredContainer) {
                filteredContainer = document.createElement('div');
                filteredContainer.id = 'filtered-results';
                filteredContainer.className = 'topic-container';
                document.querySelector('.topic-pages').appendChild(filteredContainer);
            }
            
            filteredContainer.innerHTML = '';
            
            const header = document.createElement('div');
            header.className = 'topic-page-header';
            header.innerHTML = `
                <h1>Research Path: ${tag.split('-').map(word => word.charAt(0).toUpperCase() + word.slice(1)).join(' ')}</h1>
                <p>A curated collection of resources for this research path.</p>
            `;
            filteredContainer.appendChild(header);
            
            const matchingEntries = document.querySelectorAll(`.bib-entry[data-tags*="${tag}"]`);
            
            const entriesContainer = document.createElement('div');
            entriesContainer.className = 'bibliography-container';
            filteredContainer.appendChild(entriesContainer);
            
            if (matchingEntries.length === 0) {
                entriesContainer.innerHTML = '<p>No entries found for this research path. Please check again as our collection grows.</p>';
            } else {
                const entriesArray = Array.from(matchingEntries);
                
                entriesArray.sort((a, b) => {
                    const textA = a.querySelector('.bib-citation').textContent.trim().toLowerCase();
                    const textB = b.querySelector('.bib-citation').textContent.trim().toLowerCase();
                    return textA.localeCompare(textB);
                });
                
                entriesArray.forEach(originalEntry => {
                    const clonedEntry = originalEntry.cloneNode(true);
                    
                    const viewAnnotationsButton = clonedEntry.querySelector('.bib-button:nth-child(2)');
                    if (viewAnnotationsButton) {
                        const onclick = viewAnnotationsButton.getAttribute('onclick');
                        if (onclick) {
                            const match = onclick.match(/toggleAnnotation\('([^']+)'\)/);
                            if (match && match[1]) {
                                const baseId = match[1];
                                
                                const originalAnnotationContainer = document.getElementById(`${baseId}-annotation`);
                                if (originalAnnotationContainer) {
                                    const clonedAnnotationContainer = originalAnnotationContainer.cloneNode(true);
                                    clonedEntry.appendChild(clonedAnnotationContainer);
                                    
                                    viewAnnotationsButton.removeAttribute('onclick');
                                    viewAnnotationsButton.addEventListener('click', function() {
                                        const annotationContainer = clonedEntry.querySelector('.bib-annotation-container');
                                        if (annotationContainer) {
                                            const isVisible = annotationContainer.style.display === 'block';
                                            if (isVisible) {
                                                annotationContainer.style.display = 'none';
                                            } else {
                                                entriesContainer.querySelectorAll('.bib-annotation-container').forEach(container => {
                                                    container.style.display = 'none';
                                                });
                                                
                                                annotationContainer.style.display = 'block';
                                                
                                                setTimeout(() => {
                                                    annotationContainer.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                                                }, 50);
                                            }
                                        }
                                    });
                                }
                            }
                        }
                    }
                    
                    const viewSourceButton = clonedEntry.querySelector('.bib-button:nth-child(1)');
                    if (viewSourceButton) {
                        viewSourceButton.removeAttribute('onclick');
                        viewSourceButton.addEventListener('click', function() {
                            const citation = this.closest('.bib-citation');
                            const sourceUrl = citation.getAttribute('data-source-url');
                            if (sourceUrl) {
                                window.open(sourceUrl, '_blank');
                            }
                        });
                    }
                    
                    const addPerspectiveBtn = clonedEntry.querySelector('.add-perspective-btn');
                    if (addPerspectiveBtn) {
                        addPerspectiveBtn.removeAttribute('onclick');
                        addPerspectiveBtn.addEventListener('click', function(e) {
                            e.preventDefault();
                            openContributePopup();
                        });
                    }
                    
                    entriesContainer.appendChild(clonedEntry);
                });
            }
            
            filteredContainer.style.display = 'block';
            
            document.querySelector('.landing-page').style.display = 'none';
            document.querySelector('.topic-pages').style.display = 'block';
            
            updateBreadcrumbs();
            window.scrollTo(0, 0);
        }

        function attachEventListenersToEntries(container) {
            container.querySelectorAll('.bib-button').forEach(button => {
                if (button.textContent.includes('View Annotations')) {
                    const newButton = button.cloneNode(true);
                    button.parentNode.replaceChild(newButton, button);
                    button = newButton;
                    
                    const onclick = button.getAttribute('onclick');
                    if (onclick && onclick.includes('toggleAnnotation')) {
                        const match = onclick.match(/toggleAnnotation\('([^']+)'\)/);
                        if (match && match[1]) {
                            const id = match[1];
                            button.addEventListener('click', function(e) {
                                e.preventDefault();
                                toggleAnnotation(id);
                            });
                        }
                    }
                }
                
                if (button.textContent.includes('View Source')) {
                    const newButton = button.cloneNode(true);
                    button.parentNode.replaceChild(newButton, button);
                    button = newButton;
                    
                    button.addEventListener('click', function(e) {
                        e.preventDefault();
                        viewSource(this);
                    });
                }
            });
            
            container.querySelectorAll('.add-perspective-btn').forEach(button => {
                const newButton = button.cloneNode(true);
                button.parentNode.replaceChild(newButton, button);
                button = newButton;
                
                button.addEventListener('click', function(e) {
                    e.preventDefault();
                    openContributePopup();
                });
            });
        }

        function updateEntryCounter() {
            console.log("Updating entry counter...");
            const entries = document.querySelectorAll('.bib-entry');
            console.log(`Found ${entries.length} bibliography entries`);
            
            const counter = document.getElementById('entry-counter');
            if (counter) {
                counter.textContent = entries.length;
                console.log(`Counter updated to: ${entries.length}`);
            } else {
                console.log("Counter element not found!");
            }
        }

        function logDebugInfo() {
            console.log("Available tags in bibliography entries:");
            const allTags = new Set();
            document.querySelectorAll('.bib-entry').forEach(entry => {
                const tags = entry.getAttribute('data-tags');
                if (tags) {
                    tags.split(',').forEach(tag => allTags.add(tag.trim()));
                }
            });
            console.log(Array.from(allTags).sort());
        }
    </script>
</body>
</html>
